{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8f70fe-f89e-40a7-8c64-c31d2839a58e",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Fine-Tuning Wav2Vec2 for Badaga ASR</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f265d4-f4fe-464c-a3b1-435138c7ca69",
   "metadata": {},
   "source": [
    "* **Wav2Vec2** is a pretrained model for Automatic Speech Recognition (ASR)  \n",
    "* *Facebook AI* presented a multi-lingual version of Wav2Vec2, called XLSR. XLSR stands for *cross-lingual speech representations* and refers to model's ability to learn speech representations that are useful across multiple languages.\n",
    "\n",
    "\n",
    "* Similar to BERT's masked language modeling objective, XLS-R learns contextualized speech representations by randomly masking feature vectors before passing them to a transformer network during self-supervised pre-training.\n",
    "\n",
    "\n",
    "![wav2vec2_structure](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/xls_r.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505f987-960f-45fe-96af-7f9209a3b01e",
   "metadata": {},
   "source": [
    "###  Checking GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8716477e-221d-4815-b400-04ae97ebb0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "print(torch.cuda.current_device())  # Should show the current GPU index\n",
    "print(torch.cuda.get_device_name(0))  # Should display the GPU name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1aebd7-d1e9-4812-9c73-78c9eeae22a5",
   "metadata": {},
   "source": [
    "###  Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d16fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import librosa\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a56b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define absolute paths\n",
    "data_directory = r\"C:\\Users\\T H E J\\Desktop\\Badaga_Corpus-v.0.1.0\"\n",
    "tagged_file = \"Badaga-v0.1.0.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb4f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# joining the path to the root directory\n",
    "tagged_file_path = os.path.join(data_directory, tagged_file)\n",
    "\n",
    "# reading the data\n",
    "data_frame = pd.read_excel(tagged_file_path)\n",
    "\n",
    "# dropping missing values\n",
    "data_frame.dropna(inplace=True)\n",
    "\n",
    "# reading the audio files\n",
    "data_frame[\"audio_file_name\"] = data_frame[\"audio_file_name\"].apply(lambda x: os.path.join(data_directory, \"clips\", x))\n",
    "\n",
    "# splitting the data based on train and test in the transcription file\n",
    "train_df = data_frame[data_frame[\"split_label\"]!=\"test\"]\n",
    "test_df = data_frame[data_frame[\"split_label\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3192b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8365, 9), (1469, 9))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the shape of the train and test\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9678762-4103-423b-a973-4d689de2b807",
   "metadata": {},
   "source": [
    "### Audio Loading and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159e53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the audio using librosa \n",
    "audio = list()\n",
    "for file in list(train_df[\"audio_file_name\"]):\n",
    "    a, s = librosa.load(file, sr=16000)\n",
    "    audio.append({\n",
    "        'path': file,\n",
    "        'array': a,\n",
    "        'sampling_rate': s\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio1 = list()\n",
    "for file in list(test_df[\"audio_file_name\"]):\n",
    "    a, s = librosa.load(file, sr=16000)\n",
    "    audio1.append({\n",
    "        'path': file,\n",
    "        'array': a,\n",
    "        'sampling_rate': s\n",
    "    })\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaec661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dictionary for both train and test by taking the audiofile and corresponding translated sentences\n",
    "train_dict = {'client_id':list(range(0, len(audio))), 'audio': audio, \"sentence\": list(train_df[\"translterated_script\"])}\n",
    "test_dict = {'client_id':list(range(len(audio), len(audio)+len(audio1))),'audio': audio1, \"sentence\": list(test_df[\"translterated_script\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a8dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset for the above created dictionary\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "test_dataset = Dataset.from_dict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a3f256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_id', 'audio', 'sentence']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the column names\n",
    "train_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459f8ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 0,\n",
       " 'audio': {'array': [-4.381633131409629e-13,\n",
       "   -4.547211402989443e-13,\n",
       "   -3.9910945642124274e-13,\n",
       "   -3.477597441785274e-13,\n",
       "   -5.892689764960823e-13,\n",
       "   -7.35186759560913e-13,\n",
       "   -1.9754379067867672e-13,\n",
       "   -6.340125906917349e-13,\n",
       "   -3.9618181239993444e-13,\n",
       "   1.3508462469273563e-13,\n",
       "   -3.499395326463095e-14,\n",
       "   -4.2430406519029795e-13,\n",
       "   1.7334330043410062e-13,\n",
       "   -4.451782367222157e-13,\n",
       "   -1.756699440861459e-13,\n",
       "   -4.5253256979356504e-13,\n",
       "   -8.702850723060762e-13,\n",
       "   1.7466076870399638e-14,\n",
       "   1.5608089094180239e-13,\n",
       "   -5.420372267347928e-13,\n",
       "   -3.7012819024961896e-13,\n",
       "   3.2685109501752463e-13,\n",
       "   -6.801431976215938e-14,\n",
       "   -3.582878893744479e-13,\n",
       "   -1.0914449140482507e-13,\n",
       "   -3.098158936429979e-13,\n",
       "   -4.894797132719286e-13,\n",
       "   -6.201866277477652e-13,\n",
       "   -9.631275811605722e-13,\n",
       "   -1.0823816615126297e-13,\n",
       "   -4.2352512013947574e-13,\n",
       "   -6.471780576722264e-13,\n",
       "   -7.760326127363715e-14,\n",
       "   3.445004698177101e-13,\n",
       "   -4.1060592968246434e-13,\n",
       "   -9.60529670124971e-14,\n",
       "   -1.017909647088415e-14,\n",
       "   2.0151568402241443e-13,\n",
       "   -1.8473360319758159e-13,\n",
       "   -4.788004845032723e-13,\n",
       "   6.292361786784315e-14,\n",
       "   1.0348785122306445e-14,\n",
       "   -5.286402825904757e-13,\n",
       "   -3.518745082635444e-13,\n",
       "   -5.910927265229474e-14,\n",
       "   -1.4359487991028042e-13,\n",
       "   -4.368519435082874e-13,\n",
       "   -1.5826226505526175e-13,\n",
       "   4.559846424057046e-13,\n",
       "   -1.9462357344224995e-14,\n",
       "   5.740050904208538e-15,\n",
       "   -4.074549129085697e-13,\n",
       "   9.46933097255645e-14,\n",
       "   2.356149129967289e-13,\n",
       "   -4.911019507725101e-13,\n",
       "   1.8375099076865797e-13,\n",
       "   9.639137361558414e-13,\n",
       "   -4.53415869303489e-13,\n",
       "   -8.386903367976761e-13,\n",
       "   3.0472450734606027e-13,\n",
       "   1.993705493665704e-15,\n",
       "   -7.838418499342414e-13,\n",
       "   8.7484503690817e-14,\n",
       "   2.941383573339118e-13,\n",
       "   2.5216046156510685e-13,\n",
       "   -1.408297577946277e-13,\n",
       "   -4.3263542704938263e-13,\n",
       "   5.190375039487716e-13,\n",
       "   -3.2847593460332003e-13,\n",
       "   -1.016547956922409e-12,\n",
       "   -7.45627247011188e-13,\n",
       "   3.075170868817312e-13,\n",
       "   -3.8260105532979954e-14,\n",
       "   -5.608961103735488e-13,\n",
       "   2.830118951691052e-13,\n",
       "   7.077655518952786e-13,\n",
       "   1.090673992093505e-12,\n",
       "   -5.932434448199797e-14,\n",
       "   -5.400598046025051e-13,\n",
       "   1.1895084526744593e-12,\n",
       "   -9.342125597416873e-13,\n",
       "   -2.2508047942820797e-12,\n",
       "   1.1689608699419485e-12,\n",
       "   5.006984952517224e-13,\n",
       "   -2.32021823629025e-12,\n",
       "   8.685459036011922e-13,\n",
       "   4.2685043867563e-12,\n",
       "   3.0379184953223393e-13,\n",
       "   -1.8080820044300006e-12,\n",
       "   -8.684166124921233e-13,\n",
       "   -8.30207755840584e-13,\n",
       "   -2.884028519473114e-12,\n",
       "   -4.902856766408892e-12,\n",
       "   -2.428373040846976e-12,\n",
       "   -1.962378827144451e-12,\n",
       "   -7.491035569628934e-12,\n",
       "   -4.041347118066696e-12,\n",
       "   1.590015120435384e-12,\n",
       "   -1.7332828965502256e-12,\n",
       "   3.5130882578005007e-12,\n",
       "   3.049642136043751e-12,\n",
       "   -3.1388997304149235e-12,\n",
       "   3.4116182101584513e-12,\n",
       "   -3.507852103408482e-13,\n",
       "   -9.877114751088989e-12,\n",
       "   3.0780105027272686e-12,\n",
       "   4.514749685213815e-12,\n",
       "   -1.2407554150772881e-11,\n",
       "   5.783984402540909e-12,\n",
       "   3.0355263441750324e-11,\n",
       "   3.1092840975521785e-12,\n",
       "   7.637098418944444e-14,\n",
       "   5.842808008249545e-12,\n",
       "   -1.7768829810305142e-11,\n",
       "   -2.6743369671566875e-11,\n",
       "   -2.0839904454894587e-11,\n",
       "   -1.4400433102912391e-11,\n",
       "   -1.9889159763586406e-11,\n",
       "   -2.127594801726307e-11,\n",
       "   -1.2708419386275871e-11,\n",
       "   -1.0224760274568645e-11,\n",
       "   -2.1962640039951964e-13,\n",
       "   5.3149290524245885e-11,\n",
       "   4.233953812549096e-11,\n",
       "   -1.925149276105209e-11,\n",
       "   -2.6993674656639044e-11,\n",
       "   -8.215703291292176e-12,\n",
       "   -1.4231900380412554e-11,\n",
       "   -2.568116205803328e-11,\n",
       "   -1.309875471977584e-11,\n",
       "   -1.634295476726777e-11,\n",
       "   -4.1149050312994095e-12,\n",
       "   2.704641892392612e-11,\n",
       "   2.811519420053976e-11,\n",
       "   9.595593417066617e-12,\n",
       "   -3.835613424096884e-11,\n",
       "   -6.831529786310853e-11,\n",
       "   -5.257390876811652e-12,\n",
       "   5.8184800727500985e-11,\n",
       "   2.5434201619822794e-11,\n",
       "   -1.2714693013726741e-11,\n",
       "   -6.525988083261325e-12,\n",
       "   -1.501309840334919e-11,\n",
       "   2.9581056354421875e-11,\n",
       "   7.440570382044598e-11,\n",
       "   7.853648981148709e-11,\n",
       "   8.288236763576151e-11,\n",
       "   2.511636211510737e-11,\n",
       "   1.1371530453385681e-11,\n",
       "   4.8503152882961587e-11,\n",
       "   3.8887365549911124e-11,\n",
       "   2.4479553800693665e-11,\n",
       "   3.595799699662727e-11,\n",
       "   7.889890130119426e-11,\n",
       "   4.066968636862178e-11,\n",
       "   -6.279218811577891e-11,\n",
       "   -1.1824705103968824e-10,\n",
       "   -1.1622879741990388e-10,\n",
       "   -6.62555565966727e-11,\n",
       "   -3.2908460678715556e-11,\n",
       "   2.9796189821018615e-11,\n",
       "   8.054504285759378e-11,\n",
       "   9.220803287579571e-11,\n",
       "   1.1214966455508346e-10,\n",
       "   9.186676419581374e-11,\n",
       "   6.231793553412857e-11,\n",
       "   8.945134910565145e-11,\n",
       "   6.992913192949146e-11,\n",
       "   2.148869623908034e-11,\n",
       "   4.298046293871316e-11,\n",
       "   4.5057221842448314e-11,\n",
       "   7.67954103086943e-11,\n",
       "   1.1495081275736396e-10,\n",
       "   1.3176648661072932e-10,\n",
       "   5.295661478776914e-11,\n",
       "   -3.647595767097833e-11,\n",
       "   -1.2618039425815741e-11,\n",
       "   1.3835164784647969e-11,\n",
       "   -3.635711523508611e-11,\n",
       "   -6.750836695212925e-11,\n",
       "   -1.60435466994846e-11,\n",
       "   3.440896526041293e-11,\n",
       "   1.8296596876465898e-11,\n",
       "   -2.4884979493711157e-11,\n",
       "   6.183745876464641e-11,\n",
       "   7.609166075006613e-11,\n",
       "   4.7237422307055965e-11,\n",
       "   4.027559188934937e-11,\n",
       "   9.467734235490965e-11,\n",
       "   1.1961404089433358e-10,\n",
       "   1.0087189417085085e-10,\n",
       "   6.451278400376736e-11,\n",
       "   6.062051555177916e-11,\n",
       "   1.0736717070969348e-10,\n",
       "   8.231806208902626e-11,\n",
       "   2.103562463107167e-11,\n",
       "   -2.839358262396452e-11,\n",
       "   6.817512700207917e-12,\n",
       "   1.0827622652642699e-11,\n",
       "   6.750972003644051e-11,\n",
       "   -5.3158203533465453e-11,\n",
       "   -7.030930698759263e-11,\n",
       "   6.144476594194259e-11,\n",
       "   1.9187032518352964e-10,\n",
       "   1.886563683051179e-10,\n",
       "   -3.463182865481862e-11,\n",
       "   -2.0809269585253531e-10,\n",
       "   -2.015883848738298e-10,\n",
       "   -6.957961984355165e-11,\n",
       "   -2.679022802209996e-12,\n",
       "   -1.4276101134580443e-11,\n",
       "   -2.0165455416609745e-10,\n",
       "   -3.4962954753581243e-10,\n",
       "   -3.040288298894467e-10,\n",
       "   -5.836366112621505e-11,\n",
       "   5.4852549585815424e-11,\n",
       "   3.8911717598066886e-11,\n",
       "   -1.365095814165329e-10,\n",
       "   -1.4276746451713507e-10,\n",
       "   -5.528327101655961e-11,\n",
       "   -8.729841849408615e-11,\n",
       "   -9.537061418374293e-11,\n",
       "   -1.762320983589305e-10,\n",
       "   -1.7491333381691732e-10,\n",
       "   -1.1365150487385733e-10,\n",
       "   -3.616557400776266e-11,\n",
       "   -8.292305037072012e-11,\n",
       "   -8.795889711032956e-11,\n",
       "   -6.424157733553315e-11,\n",
       "   2.7931152182802954e-11,\n",
       "   5.585548343289837e-11,\n",
       "   7.006905472506375e-12,\n",
       "   -1.0805195280183533e-11,\n",
       "   7.119833889124294e-11,\n",
       "   7.44357492310499e-11,\n",
       "   -3.783275082103188e-11,\n",
       "   1.797863420638368e-11,\n",
       "   6.124735441037643e-11,\n",
       "   1.5053971957890155e-11,\n",
       "   -1.1606937633246162e-10,\n",
       "   -1.3212246574578757e-10,\n",
       "   -7.575184229891008e-11,\n",
       "   -1.5690454491235073e-10,\n",
       "   -3.025191208649858e-10,\n",
       "   -2.271112742313619e-10,\n",
       "   -6.957676101926324e-11,\n",
       "   -7.287659191390627e-12,\n",
       "   -3.109433890924329e-11,\n",
       "   -3.4931224579537457e-11,\n",
       "   -3.307545903830089e-11,\n",
       "   -1.0011752538119367e-10,\n",
       "   -1.4149435963173307e-11,\n",
       "   4.1435695152802765e-11,\n",
       "   3.1329976807326076e-11,\n",
       "   8.16067005637855e-11,\n",
       "   1.385584424973274e-10,\n",
       "   1.9218981961444115e-10,\n",
       "   2.9518559818697554e-10,\n",
       "   2.8559674070116614e-10,\n",
       "   2.328346959679095e-10,\n",
       "   1.4463966135913608e-10,\n",
       "   -5.2941651063065365e-11,\n",
       "   -2.628095796541885e-10,\n",
       "   -3.530582215471867e-10,\n",
       "   -1.433125701444382e-10,\n",
       "   -4.869262978934863e-12,\n",
       "   -6.646105193963692e-11,\n",
       "   -1.1014060496972178e-10,\n",
       "   -4.6540268167083454e-11,\n",
       "   7.904571094896617e-12,\n",
       "   -1.5789974883162472e-10,\n",
       "   -1.565677865134063e-10,\n",
       "   3.0088879304779326e-11,\n",
       "   1.4380523161161562e-10,\n",
       "   3.0376612336624476e-10,\n",
       "   2.756689321259387e-10,\n",
       "   2.5011850923739587e-10,\n",
       "   1.9509414916907275e-10,\n",
       "   1.7744375413464297e-11,\n",
       "   1.5799646313485738e-10,\n",
       "   4.3786663184164354e-10,\n",
       "   3.104929924280242e-10,\n",
       "   1.2796279660887144e-11,\n",
       "   -5.52405378384524e-11,\n",
       "   2.928509518218547e-11,\n",
       "   8.45195718968128e-11,\n",
       "   1.0132890360114999e-10,\n",
       "   8.247472149669477e-11,\n",
       "   1.095268806206029e-10,\n",
       "   7.617672465043412e-11,\n",
       "   -1.8980851612671046e-11,\n",
       "   6.575288924448586e-11,\n",
       "   2.5063010694603705e-11,\n",
       "   -2.0881124607186052e-10,\n",
       "   -3.243830759558364e-10,\n",
       "   7.31118221519722e-11,\n",
       "   3.511189672344983e-10,\n",
       "   2.6178426093537155e-10,\n",
       "   2.0051033056134315e-10,\n",
       "   2.6012658693730373e-10,\n",
       "   2.810684462950519e-10,\n",
       "   2.888013161950198e-10,\n",
       "   2.2466101201601418e-10,\n",
       "   1.5745317549775706e-10,\n",
       "   9.038207682277033e-11,\n",
       "   -1.17232584750937e-10,\n",
       "   -1.1168387048510198e-10,\n",
       "   -6.424489412681922e-11,\n",
       "   -9.140840168120334e-11,\n",
       "   -1.4000441084238702e-10,\n",
       "   -1.4406664750055143e-10,\n",
       "   -1.078076239391379e-10,\n",
       "   -6.5457556909509496e-12,\n",
       "   -2.118559841446377e-11,\n",
       "   -9.97382315626183e-11,\n",
       "   -1.1240765263043073e-10,\n",
       "   -1.2121016690347375e-10,\n",
       "   -1.2838206886467418e-10,\n",
       "   2.2543845262790185e-11,\n",
       "   2.8913385574647066e-11,\n",
       "   -3.749414320686206e-11,\n",
       "   -6.401570940006707e-11,\n",
       "   8.82271339319729e-12,\n",
       "   1.8738760543257627e-10,\n",
       "   2.4690705036078953e-10,\n",
       "   2.4435725665128416e-10,\n",
       "   2.131194110077672e-10,\n",
       "   6.575226474403451e-13,\n",
       "   -9.972714321015985e-11,\n",
       "   3.7643551470400993e-11,\n",
       "   -7.071133956149112e-11,\n",
       "   -1.366514401635044e-10,\n",
       "   -2.7063899732393537e-11,\n",
       "   -4.687795290836405e-11,\n",
       "   -1.1377569719694947e-10,\n",
       "   -5.016834170312734e-12,\n",
       "   8.694290426491946e-11,\n",
       "   3.735144485372821e-11,\n",
       "   -5.694201360428863e-11,\n",
       "   1.36202174538802e-10,\n",
       "   -7.478655195125583e-11,\n",
       "   -1.7989415512786877e-10,\n",
       "   1.4084655663992862e-10,\n",
       "   1.858155052048005e-08,\n",
       "   6.046862210951076e-08,\n",
       "   7.319491146517976e-08,\n",
       "   3.586593066984278e-08,\n",
       "   1.0682358997371466e-08,\n",
       "   2.875271931657153e-08,\n",
       "   4.067840819743651e-08,\n",
       "   2.1935345984047672e-08,\n",
       "   8.128162587439647e-10,\n",
       "   -1.3067962711943437e-08,\n",
       "   -1.6273450142989532e-08,\n",
       "   1.9676527074352634e-08,\n",
       "   7.42545438470188e-08,\n",
       "   6.694107668181459e-08,\n",
       "   -1.758702738996476e-09,\n",
       "   -3.8566490445646195e-08,\n",
       "   -2.110973973401542e-08,\n",
       "   -9.933319944366303e-09,\n",
       "   9.150141089264707e-09,\n",
       "   1.0129067362640853e-07,\n",
       "   2.122872331256076e-07,\n",
       "   2.3227822509852558e-07,\n",
       "   2.048021769951447e-07,\n",
       "   2.73481788326535e-07,\n",
       "   4.521891696640523e-07,\n",
       "   6.115581641097378e-07,\n",
       "   6.48633829314349e-07,\n",
       "   5.649122840623022e-07,\n",
       "   4.376271931505471e-07,\n",
       "   3.663415668597736e-07,\n",
       "   3.69095317864776e-07,\n",
       "   3.4718163988145534e-07,\n",
       "   2.68892620169936e-07,\n",
       "   2.8365656135065365e-07,\n",
       "   4.858029001297837e-07,\n",
       "   7.168181923589145e-07,\n",
       "   8.059061542553536e-07,\n",
       "   8.140432328218594e-07,\n",
       "   8.228115575548145e-07,\n",
       "   7.254727734107291e-07,\n",
       "   4.7564731175953057e-07,\n",
       "   2.8606675073206134e-07,\n",
       "   3.270848765168921e-07,\n",
       "   4.809682536688342e-07,\n",
       "   5.913254312872596e-07,\n",
       "   6.993186048021016e-07,\n",
       "   8.907123856261023e-07,\n",
       "   1.1692836778820492e-06,\n",
       "   1.5303969576052623e-06,\n",
       "   1.88132980838418e-06,\n",
       "   1.960940153367119e-06,\n",
       "   1.6879805571079487e-06,\n",
       "   1.4121999356575543e-06,\n",
       "   1.412335677741794e-06,\n",
       "   1.4233761476134532e-06,\n",
       "   1.140323774961871e-06,\n",
       "   8.34552338346839e-07,\n",
       "   8.954414170148084e-07,\n",
       "   1.1451458021838334e-06,\n",
       "   1.2204836821183562e-06,\n",
       "   1.2412403975758934e-06,\n",
       "   1.4784229733777465e-06,\n",
       "   1.760135319273104e-06,\n",
       "   1.7923865698321606e-06,\n",
       "   1.6666419924149523e-06,\n",
       "   1.5724369859526632e-06,\n",
       "   1.4646017234554165e-06,\n",
       "   1.3822279925079783e-06,\n",
       "   1.5445020835613832e-06,\n",
       "   1.8526021676734672e-06,\n",
       "   1.9559597603802104e-06,\n",
       "   1.9885644633177435e-06,\n",
       "   2.4523305910406634e-06,\n",
       "   3.2468574318045285e-06,\n",
       "   3.719894721143646e-06,\n",
       "   3.7442046050273348e-06,\n",
       "   3.7614881875924766e-06,\n",
       "   3.7618892747559585e-06,\n",
       "   3.3024348340404686e-06,\n",
       "   2.529775883886032e-06,\n",
       "   2.0542399852274684e-06,\n",
       "   1.862643557615229e-06,\n",
       "   1.4735155673406553e-06,\n",
       "   1.0410832373963785e-06,\n",
       "   1.1523952707648277e-06,\n",
       "   1.6942520915108616e-06,\n",
       "   2.0381778540468076e-06,\n",
       "   2.1176506379561033e-06,\n",
       "   2.2875433387525845e-06,\n",
       "   2.4854866751411464e-06,\n",
       "   2.5340777938254178e-06,\n",
       "   2.7599994609772693e-06,\n",
       "   3.3340934351144824e-06,\n",
       "   3.6508192806650186e-06,\n",
       "   3.3146543501061387e-06,\n",
       "   2.963182851090096e-06,\n",
       "   3.1686065540270647e-06,\n",
       "   3.434880454733502e-06,\n",
       "   3.213312766092713e-06,\n",
       "   2.8826575544371735e-06,\n",
       "   2.790705821098527e-06,\n",
       "   2.4478595150867477e-06,\n",
       "   1.6385704384447308e-06,\n",
       "   1.1557106063264655e-06,\n",
       "   1.4839439472780214e-06,\n",
       "   1.9145195437886287e-06,\n",
       "   1.8524374354456086e-06,\n",
       "   1.810745629882149e-06,\n",
       "   2.2683748284180183e-06,\n",
       "   2.7369533199816942e-06,\n",
       "   2.7450744255475e-06,\n",
       "   2.5967922283598455e-06,\n",
       "   2.506510327293654e-06,\n",
       "   2.1341320461942814e-06,\n",
       "   1.4719648788741324e-06,\n",
       "   1.0552827234278084e-06,\n",
       "   9.787012231754488e-07,\n",
       "   8.792146104497078e-07,\n",
       "   1.0046662737295264e-06,\n",
       "   1.956515689016669e-06,\n",
       "   3.3325497952318983e-06,\n",
       "   4.0684162740944885e-06,\n",
       "   4.1359780880156904e-06,\n",
       "   4.414036993694026e-06,\n",
       "   4.900105068372795e-06,\n",
       "   4.630865078070201e-06,\n",
       "   3.4443376080162125e-06,\n",
       "   2.2832659851701465e-06,\n",
       "   1.6344422419933835e-06,\n",
       "   1.0524008757784031e-06,\n",
       "   3.1114038279156375e-07,\n",
       "   -2.0908754549964215e-07,\n",
       "   -3.218150936845632e-07,\n",
       "   -1.7257441697893228e-07,\n",
       "   3.0709409770679486e-07,\n",
       "   1.1360067446730682e-06,\n",
       "   1.7648148968874011e-06,\n",
       "   1.7582998452780885e-06,\n",
       "   1.5831144537514774e-06,\n",
       "   1.838376647356199e-06,\n",
       "   2.2349147457134677e-06,\n",
       "   2.243330072815297e-06,\n",
       "   2.1186885987845017e-06,\n",
       "   2.312837523277267e-06,\n",
       "   2.532302914914908e-06,\n",
       "   2.3690445232205093e-06,\n",
       "   2.223844603577163e-06,\n",
       "   2.599239451228641e-06,\n",
       "   3.088900939474115e-06,\n",
       "   3.035644340343424e-06,\n",
       "   2.6228717615595087e-06,\n",
       "   2.400036237304448e-06,\n",
       "   2.265347575303167e-06,\n",
       "   1.8009956193054677e-06,\n",
       "   1.1436975455580978e-06,\n",
       "   7.516248388128588e-07,\n",
       "   7.15296380349173e-07,\n",
       "   8.849683581502177e-07,\n",
       "   1.212934876093641e-06,\n",
       "   1.4877867897666874e-06,\n",
       "   1.3104200888847117e-06,\n",
       "   7.779564157317509e-07,\n",
       "   5.467150003823917e-07,\n",
       "   8.138227940435172e-07,\n",
       "   9.567945653543575e-07,\n",
       "   5.875000397281838e-07,\n",
       "   1.6119199131026107e-07,\n",
       "   9.856918126160963e-08,\n",
       "   1.2726721365652338e-07,\n",
       "   -3.0819673924042945e-08,\n",
       "   -1.3591568404081045e-07,\n",
       "   -8.679985086246234e-08,\n",
       "   -2.7551902803679695e-07,\n",
       "   -7.771472496642673e-07,\n",
       "   -1.0099597602675203e-06,\n",
       "   -7.391026315417548e-07,\n",
       "   -5.943555834164727e-07,\n",
       "   -1.0310531024515512e-06,\n",
       "   -1.559963038744172e-06,\n",
       "   -1.573263602949737e-06,\n",
       "   -1.20922550195246e-06,\n",
       "   -9.016290505314828e-07,\n",
       "   -7.860601272113854e-07,\n",
       "   -9.509339520263893e-07,\n",
       "   -1.5454143067472614e-06,\n",
       "   -2.3064603738021106e-06,\n",
       "   -2.724058731473633e-06,\n",
       "   -2.8878439479740337e-06,\n",
       "   -3.2929387998592574e-06,\n",
       "   -3.758574166567996e-06,\n",
       "   -3.6046999412064906e-06,\n",
       "   -2.975662482640473e-06,\n",
       "   -2.758497657850967e-06,\n",
       "   -3.070137154281838e-06,\n",
       "   -3.1417948775924742e-06,\n",
       "   -2.80990093415312e-06,\n",
       "   -2.730590495048091e-06,\n",
       "   -2.9467480544553837e-06,\n",
       "   -2.774762606350123e-06,\n",
       "   -2.2380386326403823e-06,\n",
       "   -2.1263947473926237e-06,\n",
       "   -2.427431809337577e-06,\n",
       "   -2.182330945288413e-06,\n",
       "   -1.1459123925305903e-06,\n",
       "   -1.2347686606517527e-07,\n",
       "   3.7159799148867023e-07,\n",
       "   4.795015229319688e-07,\n",
       "   1.3322448921826435e-07,\n",
       "   -8.023095574571926e-07,\n",
       "   -1.8399470036456478e-06,\n",
       "   -2.6534203243500087e-06,\n",
       "   -3.889558229275281e-06,\n",
       "   -5.868411790288519e-06,\n",
       "   -7.371092124230927e-06,\n",
       "   -7.323998033825774e-06,\n",
       "   -6.6227757997694425e-06,\n",
       "   -6.494330591522157e-06,\n",
       "   -6.237202796910424e-06,\n",
       "   -4.6502004806825425e-06,\n",
       "   -2.5135771011264296e-06,\n",
       "   -1.4741492577741155e-06,\n",
       "   -1.5157858115344425e-06,\n",
       "   -1.6354501894966234e-06,\n",
       "   -1.9123592664982425e-06,\n",
       "   -2.872826371458359e-06,\n",
       "   -3.95034703615238e-06,\n",
       "   -4.415201146912295e-06,\n",
       "   -4.640896804630756e-06,\n",
       "   -4.942961822962388e-06,\n",
       "   -4.69562428406789e-06,\n",
       "   -3.7573877307295334e-06,\n",
       "   -3.2633624869049527e-06,\n",
       "   -3.588117806430091e-06,\n",
       "   -3.449683845246909e-06,\n",
       "   -2.50282255365164e-06,\n",
       "   -2.3311763470701408e-06,\n",
       "   -3.662691142380936e-06,\n",
       "   -5.0488738452258985e-06,\n",
       "   -5.503705324372277e-06,\n",
       "   -5.9362005231378134e-06,\n",
       "   -6.787164238630794e-06,\n",
       "   -6.966682576603489e-06,\n",
       "   -6.301752364379354e-06,\n",
       "   -6.311936431302456e-06,\n",
       "   -7.374660526693333e-06,\n",
       "   -7.803868356859311e-06,\n",
       "   -6.832440703874454e-06,\n",
       "   -5.7984816521639004e-06,\n",
       "   -5.578143372986233e-06,\n",
       "   -5.436999344965443e-06,\n",
       "   -5.0044350246025715e-06,\n",
       "   -4.821685251954477e-06,\n",
       "   -4.613821147358976e-06,\n",
       "   -3.59554269380169e-06,\n",
       "   -2.518927885830635e-06,\n",
       "   -2.8047547857568134e-06,\n",
       "   -4.031462594866753e-06,\n",
       "   -4.808094672625884e-06,\n",
       "   -5.44423619430745e-06,\n",
       "   -7.099784397723852e-06,\n",
       "   -9.11547067516949e-06,\n",
       "   -9.998855603043921e-06,\n",
       "   -1.0017375643656123e-05,\n",
       "   -1.0212655979557894e-05,\n",
       "   -9.979744390875567e-06,\n",
       "   -8.322359462908935e-06,\n",
       "   -6.300345376075711e-06,\n",
       "   -5.579151547863148e-06,\n",
       "   -5.719547061744379e-06,\n",
       "   -5.263697858026717e-06,\n",
       "   -4.376592187327333e-06,\n",
       "   -4.150499080424197e-06,\n",
       "   -4.5633532863575965e-06,\n",
       "   -5.004482773074415e-06,\n",
       "   -5.479371793626342e-06,\n",
       "   -5.858883923792746e-06,\n",
       "   -5.49387323189876e-06,\n",
       "   -4.60026967630256e-06,\n",
       "   -4.2364395085314754e-06,\n",
       "   -4.328894647187553e-06,\n",
       "   -3.8005694023013348e-06,\n",
       "   -2.962549842777662e-06,\n",
       "   -3.313871047794237e-06,\n",
       "   -4.754236215376295e-06,\n",
       "   -5.574270744546084e-06,\n",
       "   -5.460718966787681e-06,\n",
       "   -5.89114279136993e-06,\n",
       "   -7.293623639270663e-06,\n",
       "   -8.215529305743985e-06,\n",
       "   -7.660326446057297e-06,\n",
       "   -6.242593372007832e-06,\n",
       "   -4.8323827286367305e-06,\n",
       "   -3.7323388824006543e-06,\n",
       "   -3.0953924579080194e-06,\n",
       "   -2.774112772385706e-06,\n",
       "   -2.194703029090306e-06,\n",
       "   -1.4496814628728316e-06,\n",
       "   -1.6085521110653644e-06,\n",
       "   -2.9605407689814456e-06,\n",
       "   -4.258450644556433e-06,\n",
       "   -4.62922798760701e-06,\n",
       "   -4.636392986867577e-06,\n",
       "   -4.6178415686881635e-06,\n",
       "   -3.899445800925605e-06,\n",
       "   -2.5085503239097307e-06,\n",
       "   -1.6888131995074218e-06,\n",
       "   -2.000976110139163e-06,\n",
       "   -2.509618980184314e-06,\n",
       "   -2.56588168667804e-06,\n",
       "   -2.723940724536078e-06,\n",
       "   -3.523717396092252e-06,\n",
       "   -4.598161922331201e-06,\n",
       "   -5.161859007785097e-06,\n",
       "   -4.707742391474312e-06,\n",
       "   -3.378987003088696e-06,\n",
       "   -2.196307150370558e-06,\n",
       "   -2.0536983811325626e-06,\n",
       "   -2.362229224672774e-06,\n",
       "   -1.8533349930294207e-06,\n",
       "   -6.502728524537815e-07,\n",
       "   6.68283917093504e-08,\n",
       "   1.4647486068497528e-07,\n",
       "   3.144251365938544e-07,\n",
       "   3.5436653433862375e-07,\n",
       "   -3.6961239402444335e-07,\n",
       "   -1.143748477261397e-06,\n",
       "   -8.830337492327089e-07,\n",
       "   -5.432460881138468e-08,\n",
       "   2.4773916607045976e-07,\n",
       "   9.814898760396318e-08,\n",
       "   -1.254988717391825e-07,\n",
       "   -6.309863351816603e-07,\n",
       "   -9.872127293419908e-07,\n",
       "   -4.86457395254547e-07,\n",
       "   -3.908064627466956e-07,\n",
       "   -2.409439275652403e-06,\n",
       "   -4.7161120164673775e-06,\n",
       "   -4.045597052027006e-06,\n",
       "   -1.2628418062377023e-06,\n",
       "   2.3699200824012223e-07,\n",
       "   7.164534849835036e-07,\n",
       "   2.560754865044146e-06,\n",
       "   4.097264536540024e-06,\n",
       "   2.3005743514659116e-06,\n",
       "   -6.024372396495892e-07,\n",
       "   -7.603849212500791e-07,\n",
       "   -1.939955183161146e-07,\n",
       "   -2.5393708256160608e-06,\n",
       "   -5.158258318260778e-06,\n",
       "   -4.232216724631144e-06,\n",
       "   -2.6536449695413467e-06,\n",
       "   -3.972812010033522e-06,\n",
       "   -4.712796908279415e-06,\n",
       "   -1.8364926290814765e-06,\n",
       "   2.646658288085746e-07,\n",
       "   -1.0928769142992678e-06,\n",
       "   -1.1828556125692558e-06,\n",
       "   6.430436769733205e-07,\n",
       "   -2.444458004902117e-06,\n",
       "   -9.041490557137877e-06,\n",
       "   -8.2772494351957e-06,\n",
       "   -1.9747635633393656e-06,\n",
       "   -5.216174031374976e-06,\n",
       "   -1.6384783521061763e-05,\n",
       "   -1.4754552466911264e-05,\n",
       "   2.2491321942652576e-06,\n",
       "   1.1445072232163511e-05,\n",
       "   4.894368430541363e-06,\n",
       "   2.0172806216578465e-06,\n",
       "   8.607613381172996e-06,\n",
       "   4.6964760258561e-06,\n",
       "   -1.2296996828808915e-05,\n",
       "   -1.562541729072109e-05,\n",
       "   3.492985342745669e-06,\n",
       "   1.871997483249288e-05,\n",
       "   7.153063052101061e-06,\n",
       "   -3.9245096559170634e-05,\n",
       "   -0.0001325219782302156,\n",
       "   -0.0002518248511478305,\n",
       "   -0.0002968877088278532,\n",
       "   -0.0001723240129649639,\n",
       "   7.064482633722946e-05,\n",
       "   0.0002712217392399907,\n",
       "   0.00035384169314056635,\n",
       "   0.0003894426627084613,\n",
       "   0.0004527238488662988,\n",
       "   0.00053539959480986,\n",
       "   0.0006239003269001842,\n",
       "   0.000736686575692147,\n",
       "   0.0008460143581032753,\n",
       "   0.0008861722890287638,\n",
       "   0.0008811891311779618,\n",
       "   0.0009407312609255314,\n",
       "   0.0010873139835894108,\n",
       "   0.0012127186637371778,\n",
       "   0.001242246595211327,\n",
       "   0.0012076772982254624,\n",
       "   0.0011240743333473802,\n",
       "   0.0009483826579526067,\n",
       "   0.0007081293151713908,\n",
       "   0.0005149102071300149,\n",
       "   0.00039499797276221216,\n",
       "   0.0002587204799056053,\n",
       "   8.479413372697309e-05,\n",
       "   -3.2940490200417116e-05,\n",
       "   -7.513442687923089e-05,\n",
       "   -0.00015494100807700306,\n",
       "   -0.00031873356783762574,\n",
       "   -0.0004613639903254807,\n",
       "   -0.0005097968969494104,\n",
       "   -0.0005216694553382695,\n",
       "   -0.0005390909500420094,\n",
       "   -0.0005242051556706429,\n",
       "   -0.0005063462303951383,\n",
       "   -0.0006028193747624755,\n",
       "   -0.0008108731126412749,\n",
       "   -0.0009605811210349202,\n",
       "   -0.0009602175559848547,\n",
       "   -0.000917653611395508,\n",
       "   -0.0009433999075554311,\n",
       "   -0.001010379521176219,\n",
       "   -0.0010840948671102524,\n",
       "   -0.0012089202646166086,\n",
       "   -0.0013778253924101591,\n",
       "   -0.0014839235227555037,\n",
       "   -0.0014821174554526806,\n",
       "   -0.0014433467295020819,\n",
       "   -0.0013912254944443703,\n",
       "   -0.0012586602242663503,\n",
       "   -0.001063058851286769,\n",
       "   -0.0009385772282257676,\n",
       "   -0.0009214414749294519,\n",
       "   -0.0008810987928882241,\n",
       "   -0.0007421329501084983,\n",
       "   -0.0006040600128471851,\n",
       "   -0.0005581810837611556,\n",
       "   -0.000539668370038271,\n",
       "   -0.0004479498602449894,\n",
       "   -0.000288558192551136,\n",
       "   -0.00012843818694818765,\n",
       "   -1.5651137800887227e-05,\n",
       "   2.3900787709862925e-05,\n",
       "   1.7793656297726557e-05,\n",
       "   8.097897080006078e-05,\n",
       "   0.0002954969822894782,\n",
       "   0.0005617168499156833,\n",
       "   0.0007043926743790507,\n",
       "   0.0007160968380048871,\n",
       "   0.0007472370052710176,\n",
       "   0.0008637203136458993,\n",
       "   0.0009737382642924786,\n",
       "   0.001005580648779869,\n",
       "   0.0010085857938975096,\n",
       "   0.0010513786692172289,\n",
       "   0.0011397262569516897,\n",
       "   0.0012495556147769094,\n",
       "   0.0013424735516309738,\n",
       "   0.0013523803791031241,\n",
       "   0.0012500310549512506,\n",
       "   0.0011056349612772465,\n",
       "   0.0010063534136861563,\n",
       "   0.0009446066105738282,\n",
       "   0.0008622236200608313,\n",
       "   0.0007498797494918108,\n",
       "   0.0006163467769511044,\n",
       "   0.00042279064655303955,\n",
       "   0.00014432391617447138,\n",
       "   -0.00015137906302697957,\n",
       "   -0.00036997225834056735,\n",
       "   -0.0004910118877887726,\n",
       "   -0.0005478090024553239,\n",
       "   -0.0005736174643971026,\n",
       "   -0.0006151061388663948,\n",
       "   -0.0007184225833043456,\n",
       "   -0.000850495882332325,\n",
       "   -0.0009156133164651692,\n",
       "   -0.0008888310985639691,\n",
       "   -0.000843080400954932,\n",
       "   -0.0008226054487749934,\n",
       "   -0.0008006145944818854,\n",
       "   -0.0007823477499186993,\n",
       "   -0.000818124448414892,\n",
       "   -0.0008827643468976021,\n",
       "   -0.000877995858900249,\n",
       "   -0.0007919360650703311,\n",
       "   -0.0007264702580869198,\n",
       "   -0.000739302602596581,\n",
       "   -0.000791452475823462,\n",
       "   -0.0008648865623399615,\n",
       "   -0.000983883859589696,\n",
       "   -0.0011047087609767914,\n",
       "   -0.0011447659926488996,\n",
       "   -0.0011416689958423376,\n",
       "   -0.0012192294234409928,\n",
       "   -0.001374602084979415,\n",
       "   -0.0014671984827145934,\n",
       "   -0.001439157989807427,\n",
       "   -0.0013725175522267818,\n",
       "   -0.0013059743214398623,\n",
       "   -0.0011859764344990253,\n",
       "   -0.0010436634765937924,\n",
       "   -0.0010240939445793629,\n",
       "   -0.0011618982534855604,\n",
       "   -0.0012880819849669933,\n",
       "   -0.0012444952735677361,\n",
       "   -0.0010670132469385862,\n",
       "   -0.0008913702913559973,\n",
       "   -0.0007909383857622743,\n",
       "   -0.0007587102008983493,\n",
       "   -0.0007452272693626583,\n",
       "   -0.0006720233941450715,\n",
       "   -0.0004991869209334254,\n",
       "   -0.00029804304358549416,\n",
       "   -0.0001643152500037104,\n",
       "   -6.305763963609934e-05,\n",
       "   0.0001248140906682238,\n",
       "   0.00040175742469727993,\n",
       "   0.0006363099091686308,\n",
       "   0.0007693130755797029,\n",
       "   0.000900760293006897,\n",
       "   0.0011145186144858599,\n",
       "   0.001328016398474574,\n",
       "   0.0013997675850987434,\n",
       "   0.0013231838820502162,\n",
       "   0.0012403397122398019,\n",
       "   0.0012839981354773045,\n",
       "   0.0014488489832729101,\n",
       "   0.0016122099477797747,\n",
       "   0.0016608941368758678,\n",
       "   0.0015950938686728477,\n",
       "   0.001506850472651422,\n",
       "   0.001465515815652907,\n",
       "   0.0014500009128823876,\n",
       "   0.0013980179792270064,\n",
       "   0.0012882057344540954,\n",
       "   0.0011564388405531645,\n",
       "   0.0010518701747059822,\n",
       "   0.0009904381586238742,\n",
       "   0.0009431095095351338,\n",
       "   0.000875891069881618,\n",
       "   0.0008068041643127799,\n",
       "   0.0007878592004999518,\n",
       "   0.0008090756018646061,\n",
       "   0.0007726547191850841,\n",
       "   0.0006125420331954956,\n",
       "   0.00039160955930128694,\n",
       "   0.00021815174841322005,\n",
       "   0.00011316748714307323,\n",
       "   3.169586125295609e-05,\n",
       "   -3.394792656763457e-05,\n",
       "   -6.295675120782107e-05,\n",
       "   -8.057360537350178e-05,\n",
       "   -0.00012920194421894848,\n",
       "   -0.00018761976389214396,\n",
       "   -0.0002055745862890035,\n",
       "   -0.00019597513892222196,\n",
       "   -0.00021024409215897322,\n",
       "   -0.0002455689827911556,\n",
       "   -0.00025894970167428255,\n",
       "   -0.0002534321101848036,\n",
       "   -0.0002657596778590232,\n",
       "   -0.0002885031281039119,\n",
       "   -0.0002849313314072788,\n",
       "   -0.00026481255190446973,\n",
       "   -0.0002681900514289737,\n",
       "   -0.0002887207083404064,\n",
       "   -0.00028754823142662644,\n",
       "   -0.00026771827833727,\n",
       "   -0.0002646106877364218,\n",
       "   -0.0002766655234154314,\n",
       "   -0.0002722134522628039,\n",
       "   -0.0002523540169931948,\n",
       "   -0.00024661788484081626,\n",
       "   -0.00025600779918022454,\n",
       "   -0.0002558420819696039,\n",
       "   -0.00024295850016642362,\n",
       "   -0.0002340662176720798,\n",
       "   -0.00023027686984278262,\n",
       "   -0.00022272983915172517,\n",
       "   -0.000216341795749031,\n",
       "   -0.00021494796965271235,\n",
       "   -0.00020489699090830982,\n",
       "   -0.00018164326320402324,\n",
       "   -0.00016689737094566226,\n",
       "   -0.00016917940229177475,\n",
       "   -0.00016154641343746334,\n",
       "   -0.00012755616626236588,\n",
       "   -9.4452771008946e-05,\n",
       "   -8.85134722921066e-05,\n",
       "   -9.19222438824363e-05,\n",
       "   -7.731854566372931e-05,\n",
       "   -5.403402974479832e-05,\n",
       "   -4.60139344795607e-05,\n",
       "   -4.9240356020163745e-05,\n",
       "   -4.411057670949958e-05,\n",
       "   -2.8277812816668302e-05,\n",
       "   -1.3356077033677138e-05,\n",
       "   -5.4923671086726245e-06,\n",
       "   -6.527740879391786e-06,\n",
       "   -1.65467536135111e-05,\n",
       "   -2.350477734580636e-05,\n",
       "   -1.2041008631058503e-05,\n",
       "   9.476991181145422e-06,\n",
       "   1.4890762940922286e-05,\n",
       "   -8.995152711577248e-07,\n",
       "   -1.4633979844802525e-05,\n",
       "   -1.2388916729833e-05,\n",
       "   -7.412662398564862e-06,\n",
       "   -1.3504708476830274e-05,\n",
       "   -2.551635952841025e-05,\n",
       "   -3.470298179308884e-05,\n",
       "   -4.093161260243505e-05,\n",
       "   -4.272969817975536e-05,\n",
       "   -3.60443809768185e-05,\n",
       "   -2.6150522899115458e-05,\n",
       "   -2.3028354917187244e-05,\n",
       "   -2.2007552615832537e-05,\n",
       "   -1.088394765247358e-05,\n",
       "   5.76416732656071e-06,\n",
       "   9.672410669736564e-06,\n",
       "   -1.9208303001505556e-06,\n",
       "   -1.0894322258536704e-05,\n",
       "   -6.212748758116504e-06,\n",
       "   1.9739309209398925e-06,\n",
       "   1.24237624277157e-06,\n",
       "   -5.039416009822162e-06,\n",
       "   -6.049647709005512e-06,\n",
       "   1.988248641282553e-06,\n",
       "   1.2896429325337522e-05,\n",
       "   1.7749702237779275e-05,\n",
       "   1.2860680726589635e-05,\n",
       "   3.880961230606772e-06,\n",
       "   -9.111512326853699e-07,\n",
       "   -2.3690447505941847e-06,\n",
       "   -1.0020296031143516e-05,\n",
       "   -2.6243309548590332e-05,\n",
       "   -4.0660612285137177e-05,\n",
       "   -4.4957072532270104e-05,\n",
       "   -4.339642691775225e-05,\n",
       "   -4.326905036577955e-05,\n",
       "   -4.333285323809832e-05,\n",
       "   -4.07532716053538e-05,\n",
       "   -3.901200398104265e-05,\n",
       "   -4.078017809661105e-05,\n",
       "   -3.951753387809731e-05,\n",
       "   -2.9793140129186213e-05,\n",
       "   -1.870043524831999e-05,\n",
       "   -1.6758391211624257e-05,\n",
       "   -2.2145643015392125e-05,\n",
       "   -2.3615750251337886e-05,\n",
       "   -1.6911026250454597e-05,\n",
       "   -8.226933459809516e-06,\n",
       "   -3.1612707971362397e-06,\n",
       "   -4.6563221189899195e-07,\n",
       "   1.7982904410018818e-06,\n",
       "   2.912174750235863e-06,\n",
       "   2.646770099090645e-06,\n",
       "   ...],\n",
       "  'path': 'C:\\\\Users\\\\T H E J\\\\Desktop\\\\Badaga_Corpus-v.0.1.0\\\\clips\\\\F002_1_1.mp3',\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': 'manaya aena udhaka'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first column using index\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139319b5-4b14-410b-92fb-6d324e804da0",
   "metadata": {},
   "source": [
    "### Text Cleaning: Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4df3a6-af68-4475-8d41-d9813068594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the special characters\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).upper() + \" \"\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd81a4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████| 8365/8365 [00:01<00:00, 5172.07 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████| 1469/1469 [00:00<00:00, 9757.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# removing the special characters from train and test using map function\n",
    "train_dataset = train_dataset.map(remove_special_characters)\n",
    "test_dataset = test_dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a95f092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 0,\n",
       " 'audio': {'array': [-4.381633131409629e-13,\n",
       "   -4.547211402989443e-13,\n",
       "   -3.9910945642124274e-13,\n",
       "   -3.477597441785274e-13,\n",
       "   -5.892689764960823e-13,\n",
       "   -7.35186759560913e-13,\n",
       "   -1.9754379067867672e-13,\n",
       "   -6.340125906917349e-13,\n",
       "   -3.9618181239993444e-13,\n",
       "   1.3508462469273563e-13,\n",
       "   -3.499395326463095e-14,\n",
       "   -4.2430406519029795e-13,\n",
       "   1.7334330043410062e-13,\n",
       "   -4.451782367222157e-13,\n",
       "   -1.756699440861459e-13,\n",
       "   -4.5253256979356504e-13,\n",
       "   -8.702850723060762e-13,\n",
       "   1.7466076870399638e-14,\n",
       "   1.5608089094180239e-13,\n",
       "   -5.420372267347928e-13,\n",
       "   -3.7012819024961896e-13,\n",
       "   3.2685109501752463e-13,\n",
       "   -6.801431976215938e-14,\n",
       "   -3.582878893744479e-13,\n",
       "   -1.0914449140482507e-13,\n",
       "   -3.098158936429979e-13,\n",
       "   -4.894797132719286e-13,\n",
       "   -6.201866277477652e-13,\n",
       "   -9.631275811605722e-13,\n",
       "   -1.0823816615126297e-13,\n",
       "   -4.2352512013947574e-13,\n",
       "   -6.471780576722264e-13,\n",
       "   -7.760326127363715e-14,\n",
       "   3.445004698177101e-13,\n",
       "   -4.1060592968246434e-13,\n",
       "   -9.60529670124971e-14,\n",
       "   -1.017909647088415e-14,\n",
       "   2.0151568402241443e-13,\n",
       "   -1.8473360319758159e-13,\n",
       "   -4.788004845032723e-13,\n",
       "   6.292361786784315e-14,\n",
       "   1.0348785122306445e-14,\n",
       "   -5.286402825904757e-13,\n",
       "   -3.518745082635444e-13,\n",
       "   -5.910927265229474e-14,\n",
       "   -1.4359487991028042e-13,\n",
       "   -4.368519435082874e-13,\n",
       "   -1.5826226505526175e-13,\n",
       "   4.559846424057046e-13,\n",
       "   -1.9462357344224995e-14,\n",
       "   5.740050904208538e-15,\n",
       "   -4.074549129085697e-13,\n",
       "   9.46933097255645e-14,\n",
       "   2.356149129967289e-13,\n",
       "   -4.911019507725101e-13,\n",
       "   1.8375099076865797e-13,\n",
       "   9.639137361558414e-13,\n",
       "   -4.53415869303489e-13,\n",
       "   -8.386903367976761e-13,\n",
       "   3.0472450734606027e-13,\n",
       "   1.993705493665704e-15,\n",
       "   -7.838418499342414e-13,\n",
       "   8.7484503690817e-14,\n",
       "   2.941383573339118e-13,\n",
       "   2.5216046156510685e-13,\n",
       "   -1.408297577946277e-13,\n",
       "   -4.3263542704938263e-13,\n",
       "   5.190375039487716e-13,\n",
       "   -3.2847593460332003e-13,\n",
       "   -1.016547956922409e-12,\n",
       "   -7.45627247011188e-13,\n",
       "   3.075170868817312e-13,\n",
       "   -3.8260105532979954e-14,\n",
       "   -5.608961103735488e-13,\n",
       "   2.830118951691052e-13,\n",
       "   7.077655518952786e-13,\n",
       "   1.090673992093505e-12,\n",
       "   -5.932434448199797e-14,\n",
       "   -5.400598046025051e-13,\n",
       "   1.1895084526744593e-12,\n",
       "   -9.342125597416873e-13,\n",
       "   -2.2508047942820797e-12,\n",
       "   1.1689608699419485e-12,\n",
       "   5.006984952517224e-13,\n",
       "   -2.32021823629025e-12,\n",
       "   8.685459036011922e-13,\n",
       "   4.2685043867563e-12,\n",
       "   3.0379184953223393e-13,\n",
       "   -1.8080820044300006e-12,\n",
       "   -8.684166124921233e-13,\n",
       "   -8.30207755840584e-13,\n",
       "   -2.884028519473114e-12,\n",
       "   -4.902856766408892e-12,\n",
       "   -2.428373040846976e-12,\n",
       "   -1.962378827144451e-12,\n",
       "   -7.491035569628934e-12,\n",
       "   -4.041347118066696e-12,\n",
       "   1.590015120435384e-12,\n",
       "   -1.7332828965502256e-12,\n",
       "   3.5130882578005007e-12,\n",
       "   3.049642136043751e-12,\n",
       "   -3.1388997304149235e-12,\n",
       "   3.4116182101584513e-12,\n",
       "   -3.507852103408482e-13,\n",
       "   -9.877114751088989e-12,\n",
       "   3.0780105027272686e-12,\n",
       "   4.514749685213815e-12,\n",
       "   -1.2407554150772881e-11,\n",
       "   5.783984402540909e-12,\n",
       "   3.0355263441750324e-11,\n",
       "   3.1092840975521785e-12,\n",
       "   7.637098418944444e-14,\n",
       "   5.842808008249545e-12,\n",
       "   -1.7768829810305142e-11,\n",
       "   -2.6743369671566875e-11,\n",
       "   -2.0839904454894587e-11,\n",
       "   -1.4400433102912391e-11,\n",
       "   -1.9889159763586406e-11,\n",
       "   -2.127594801726307e-11,\n",
       "   -1.2708419386275871e-11,\n",
       "   -1.0224760274568645e-11,\n",
       "   -2.1962640039951964e-13,\n",
       "   5.3149290524245885e-11,\n",
       "   4.233953812549096e-11,\n",
       "   -1.925149276105209e-11,\n",
       "   -2.6993674656639044e-11,\n",
       "   -8.215703291292176e-12,\n",
       "   -1.4231900380412554e-11,\n",
       "   -2.568116205803328e-11,\n",
       "   -1.309875471977584e-11,\n",
       "   -1.634295476726777e-11,\n",
       "   -4.1149050312994095e-12,\n",
       "   2.704641892392612e-11,\n",
       "   2.811519420053976e-11,\n",
       "   9.595593417066617e-12,\n",
       "   -3.835613424096884e-11,\n",
       "   -6.831529786310853e-11,\n",
       "   -5.257390876811652e-12,\n",
       "   5.8184800727500985e-11,\n",
       "   2.5434201619822794e-11,\n",
       "   -1.2714693013726741e-11,\n",
       "   -6.525988083261325e-12,\n",
       "   -1.501309840334919e-11,\n",
       "   2.9581056354421875e-11,\n",
       "   7.440570382044598e-11,\n",
       "   7.853648981148709e-11,\n",
       "   8.288236763576151e-11,\n",
       "   2.511636211510737e-11,\n",
       "   1.1371530453385681e-11,\n",
       "   4.8503152882961587e-11,\n",
       "   3.8887365549911124e-11,\n",
       "   2.4479553800693665e-11,\n",
       "   3.595799699662727e-11,\n",
       "   7.889890130119426e-11,\n",
       "   4.066968636862178e-11,\n",
       "   -6.279218811577891e-11,\n",
       "   -1.1824705103968824e-10,\n",
       "   -1.1622879741990388e-10,\n",
       "   -6.62555565966727e-11,\n",
       "   -3.2908460678715556e-11,\n",
       "   2.9796189821018615e-11,\n",
       "   8.054504285759378e-11,\n",
       "   9.220803287579571e-11,\n",
       "   1.1214966455508346e-10,\n",
       "   9.186676419581374e-11,\n",
       "   6.231793553412857e-11,\n",
       "   8.945134910565145e-11,\n",
       "   6.992913192949146e-11,\n",
       "   2.148869623908034e-11,\n",
       "   4.298046293871316e-11,\n",
       "   4.5057221842448314e-11,\n",
       "   7.67954103086943e-11,\n",
       "   1.1495081275736396e-10,\n",
       "   1.3176648661072932e-10,\n",
       "   5.295661478776914e-11,\n",
       "   -3.647595767097833e-11,\n",
       "   -1.2618039425815741e-11,\n",
       "   1.3835164784647969e-11,\n",
       "   -3.635711523508611e-11,\n",
       "   -6.750836695212925e-11,\n",
       "   -1.60435466994846e-11,\n",
       "   3.440896526041293e-11,\n",
       "   1.8296596876465898e-11,\n",
       "   -2.4884979493711157e-11,\n",
       "   6.183745876464641e-11,\n",
       "   7.609166075006613e-11,\n",
       "   4.7237422307055965e-11,\n",
       "   4.027559188934937e-11,\n",
       "   9.467734235490965e-11,\n",
       "   1.1961404089433358e-10,\n",
       "   1.0087189417085085e-10,\n",
       "   6.451278400376736e-11,\n",
       "   6.062051555177916e-11,\n",
       "   1.0736717070969348e-10,\n",
       "   8.231806208902626e-11,\n",
       "   2.103562463107167e-11,\n",
       "   -2.839358262396452e-11,\n",
       "   6.817512700207917e-12,\n",
       "   1.0827622652642699e-11,\n",
       "   6.750972003644051e-11,\n",
       "   -5.3158203533465453e-11,\n",
       "   -7.030930698759263e-11,\n",
       "   6.144476594194259e-11,\n",
       "   1.9187032518352964e-10,\n",
       "   1.886563683051179e-10,\n",
       "   -3.463182865481862e-11,\n",
       "   -2.0809269585253531e-10,\n",
       "   -2.015883848738298e-10,\n",
       "   -6.957961984355165e-11,\n",
       "   -2.679022802209996e-12,\n",
       "   -1.4276101134580443e-11,\n",
       "   -2.0165455416609745e-10,\n",
       "   -3.4962954753581243e-10,\n",
       "   -3.040288298894467e-10,\n",
       "   -5.836366112621505e-11,\n",
       "   5.4852549585815424e-11,\n",
       "   3.8911717598066886e-11,\n",
       "   -1.365095814165329e-10,\n",
       "   -1.4276746451713507e-10,\n",
       "   -5.528327101655961e-11,\n",
       "   -8.729841849408615e-11,\n",
       "   -9.537061418374293e-11,\n",
       "   -1.762320983589305e-10,\n",
       "   -1.7491333381691732e-10,\n",
       "   -1.1365150487385733e-10,\n",
       "   -3.616557400776266e-11,\n",
       "   -8.292305037072012e-11,\n",
       "   -8.795889711032956e-11,\n",
       "   -6.424157733553315e-11,\n",
       "   2.7931152182802954e-11,\n",
       "   5.585548343289837e-11,\n",
       "   7.006905472506375e-12,\n",
       "   -1.0805195280183533e-11,\n",
       "   7.119833889124294e-11,\n",
       "   7.44357492310499e-11,\n",
       "   -3.783275082103188e-11,\n",
       "   1.797863420638368e-11,\n",
       "   6.124735441037643e-11,\n",
       "   1.5053971957890155e-11,\n",
       "   -1.1606937633246162e-10,\n",
       "   -1.3212246574578757e-10,\n",
       "   -7.575184229891008e-11,\n",
       "   -1.5690454491235073e-10,\n",
       "   -3.025191208649858e-10,\n",
       "   -2.271112742313619e-10,\n",
       "   -6.957676101926324e-11,\n",
       "   -7.287659191390627e-12,\n",
       "   -3.109433890924329e-11,\n",
       "   -3.4931224579537457e-11,\n",
       "   -3.307545903830089e-11,\n",
       "   -1.0011752538119367e-10,\n",
       "   -1.4149435963173307e-11,\n",
       "   4.1435695152802765e-11,\n",
       "   3.1329976807326076e-11,\n",
       "   8.16067005637855e-11,\n",
       "   1.385584424973274e-10,\n",
       "   1.9218981961444115e-10,\n",
       "   2.9518559818697554e-10,\n",
       "   2.8559674070116614e-10,\n",
       "   2.328346959679095e-10,\n",
       "   1.4463966135913608e-10,\n",
       "   -5.2941651063065365e-11,\n",
       "   -2.628095796541885e-10,\n",
       "   -3.530582215471867e-10,\n",
       "   -1.433125701444382e-10,\n",
       "   -4.869262978934863e-12,\n",
       "   -6.646105193963692e-11,\n",
       "   -1.1014060496972178e-10,\n",
       "   -4.6540268167083454e-11,\n",
       "   7.904571094896617e-12,\n",
       "   -1.5789974883162472e-10,\n",
       "   -1.565677865134063e-10,\n",
       "   3.0088879304779326e-11,\n",
       "   1.4380523161161562e-10,\n",
       "   3.0376612336624476e-10,\n",
       "   2.756689321259387e-10,\n",
       "   2.5011850923739587e-10,\n",
       "   1.9509414916907275e-10,\n",
       "   1.7744375413464297e-11,\n",
       "   1.5799646313485738e-10,\n",
       "   4.3786663184164354e-10,\n",
       "   3.104929924280242e-10,\n",
       "   1.2796279660887144e-11,\n",
       "   -5.52405378384524e-11,\n",
       "   2.928509518218547e-11,\n",
       "   8.45195718968128e-11,\n",
       "   1.0132890360114999e-10,\n",
       "   8.247472149669477e-11,\n",
       "   1.095268806206029e-10,\n",
       "   7.617672465043412e-11,\n",
       "   -1.8980851612671046e-11,\n",
       "   6.575288924448586e-11,\n",
       "   2.5063010694603705e-11,\n",
       "   -2.0881124607186052e-10,\n",
       "   -3.243830759558364e-10,\n",
       "   7.31118221519722e-11,\n",
       "   3.511189672344983e-10,\n",
       "   2.6178426093537155e-10,\n",
       "   2.0051033056134315e-10,\n",
       "   2.6012658693730373e-10,\n",
       "   2.810684462950519e-10,\n",
       "   2.888013161950198e-10,\n",
       "   2.2466101201601418e-10,\n",
       "   1.5745317549775706e-10,\n",
       "   9.038207682277033e-11,\n",
       "   -1.17232584750937e-10,\n",
       "   -1.1168387048510198e-10,\n",
       "   -6.424489412681922e-11,\n",
       "   -9.140840168120334e-11,\n",
       "   -1.4000441084238702e-10,\n",
       "   -1.4406664750055143e-10,\n",
       "   -1.078076239391379e-10,\n",
       "   -6.5457556909509496e-12,\n",
       "   -2.118559841446377e-11,\n",
       "   -9.97382315626183e-11,\n",
       "   -1.1240765263043073e-10,\n",
       "   -1.2121016690347375e-10,\n",
       "   -1.2838206886467418e-10,\n",
       "   2.2543845262790185e-11,\n",
       "   2.8913385574647066e-11,\n",
       "   -3.749414320686206e-11,\n",
       "   -6.401570940006707e-11,\n",
       "   8.82271339319729e-12,\n",
       "   1.8738760543257627e-10,\n",
       "   2.4690705036078953e-10,\n",
       "   2.4435725665128416e-10,\n",
       "   2.131194110077672e-10,\n",
       "   6.575226474403451e-13,\n",
       "   -9.972714321015985e-11,\n",
       "   3.7643551470400993e-11,\n",
       "   -7.071133956149112e-11,\n",
       "   -1.366514401635044e-10,\n",
       "   -2.7063899732393537e-11,\n",
       "   -4.687795290836405e-11,\n",
       "   -1.1377569719694947e-10,\n",
       "   -5.016834170312734e-12,\n",
       "   8.694290426491946e-11,\n",
       "   3.735144485372821e-11,\n",
       "   -5.694201360428863e-11,\n",
       "   1.36202174538802e-10,\n",
       "   -7.478655195125583e-11,\n",
       "   -1.7989415512786877e-10,\n",
       "   1.4084655663992862e-10,\n",
       "   1.858155052048005e-08,\n",
       "   6.046862210951076e-08,\n",
       "   7.319491146517976e-08,\n",
       "   3.586593066984278e-08,\n",
       "   1.0682358997371466e-08,\n",
       "   2.875271931657153e-08,\n",
       "   4.067840819743651e-08,\n",
       "   2.1935345984047672e-08,\n",
       "   8.128162587439647e-10,\n",
       "   -1.3067962711943437e-08,\n",
       "   -1.6273450142989532e-08,\n",
       "   1.9676527074352634e-08,\n",
       "   7.42545438470188e-08,\n",
       "   6.694107668181459e-08,\n",
       "   -1.758702738996476e-09,\n",
       "   -3.8566490445646195e-08,\n",
       "   -2.110973973401542e-08,\n",
       "   -9.933319944366303e-09,\n",
       "   9.150141089264707e-09,\n",
       "   1.0129067362640853e-07,\n",
       "   2.122872331256076e-07,\n",
       "   2.3227822509852558e-07,\n",
       "   2.048021769951447e-07,\n",
       "   2.73481788326535e-07,\n",
       "   4.521891696640523e-07,\n",
       "   6.115581641097378e-07,\n",
       "   6.48633829314349e-07,\n",
       "   5.649122840623022e-07,\n",
       "   4.376271931505471e-07,\n",
       "   3.663415668597736e-07,\n",
       "   3.69095317864776e-07,\n",
       "   3.4718163988145534e-07,\n",
       "   2.68892620169936e-07,\n",
       "   2.8365656135065365e-07,\n",
       "   4.858029001297837e-07,\n",
       "   7.168181923589145e-07,\n",
       "   8.059061542553536e-07,\n",
       "   8.140432328218594e-07,\n",
       "   8.228115575548145e-07,\n",
       "   7.254727734107291e-07,\n",
       "   4.7564731175953057e-07,\n",
       "   2.8606675073206134e-07,\n",
       "   3.270848765168921e-07,\n",
       "   4.809682536688342e-07,\n",
       "   5.913254312872596e-07,\n",
       "   6.993186048021016e-07,\n",
       "   8.907123856261023e-07,\n",
       "   1.1692836778820492e-06,\n",
       "   1.5303969576052623e-06,\n",
       "   1.88132980838418e-06,\n",
       "   1.960940153367119e-06,\n",
       "   1.6879805571079487e-06,\n",
       "   1.4121999356575543e-06,\n",
       "   1.412335677741794e-06,\n",
       "   1.4233761476134532e-06,\n",
       "   1.140323774961871e-06,\n",
       "   8.34552338346839e-07,\n",
       "   8.954414170148084e-07,\n",
       "   1.1451458021838334e-06,\n",
       "   1.2204836821183562e-06,\n",
       "   1.2412403975758934e-06,\n",
       "   1.4784229733777465e-06,\n",
       "   1.760135319273104e-06,\n",
       "   1.7923865698321606e-06,\n",
       "   1.6666419924149523e-06,\n",
       "   1.5724369859526632e-06,\n",
       "   1.4646017234554165e-06,\n",
       "   1.3822279925079783e-06,\n",
       "   1.5445020835613832e-06,\n",
       "   1.8526021676734672e-06,\n",
       "   1.9559597603802104e-06,\n",
       "   1.9885644633177435e-06,\n",
       "   2.4523305910406634e-06,\n",
       "   3.2468574318045285e-06,\n",
       "   3.719894721143646e-06,\n",
       "   3.7442046050273348e-06,\n",
       "   3.7614881875924766e-06,\n",
       "   3.7618892747559585e-06,\n",
       "   3.3024348340404686e-06,\n",
       "   2.529775883886032e-06,\n",
       "   2.0542399852274684e-06,\n",
       "   1.862643557615229e-06,\n",
       "   1.4735155673406553e-06,\n",
       "   1.0410832373963785e-06,\n",
       "   1.1523952707648277e-06,\n",
       "   1.6942520915108616e-06,\n",
       "   2.0381778540468076e-06,\n",
       "   2.1176506379561033e-06,\n",
       "   2.2875433387525845e-06,\n",
       "   2.4854866751411464e-06,\n",
       "   2.5340777938254178e-06,\n",
       "   2.7599994609772693e-06,\n",
       "   3.3340934351144824e-06,\n",
       "   3.6508192806650186e-06,\n",
       "   3.3146543501061387e-06,\n",
       "   2.963182851090096e-06,\n",
       "   3.1686065540270647e-06,\n",
       "   3.434880454733502e-06,\n",
       "   3.213312766092713e-06,\n",
       "   2.8826575544371735e-06,\n",
       "   2.790705821098527e-06,\n",
       "   2.4478595150867477e-06,\n",
       "   1.6385704384447308e-06,\n",
       "   1.1557106063264655e-06,\n",
       "   1.4839439472780214e-06,\n",
       "   1.9145195437886287e-06,\n",
       "   1.8524374354456086e-06,\n",
       "   1.810745629882149e-06,\n",
       "   2.2683748284180183e-06,\n",
       "   2.7369533199816942e-06,\n",
       "   2.7450744255475e-06,\n",
       "   2.5967922283598455e-06,\n",
       "   2.506510327293654e-06,\n",
       "   2.1341320461942814e-06,\n",
       "   1.4719648788741324e-06,\n",
       "   1.0552827234278084e-06,\n",
       "   9.787012231754488e-07,\n",
       "   8.792146104497078e-07,\n",
       "   1.0046662737295264e-06,\n",
       "   1.956515689016669e-06,\n",
       "   3.3325497952318983e-06,\n",
       "   4.0684162740944885e-06,\n",
       "   4.1359780880156904e-06,\n",
       "   4.414036993694026e-06,\n",
       "   4.900105068372795e-06,\n",
       "   4.630865078070201e-06,\n",
       "   3.4443376080162125e-06,\n",
       "   2.2832659851701465e-06,\n",
       "   1.6344422419933835e-06,\n",
       "   1.0524008757784031e-06,\n",
       "   3.1114038279156375e-07,\n",
       "   -2.0908754549964215e-07,\n",
       "   -3.218150936845632e-07,\n",
       "   -1.7257441697893228e-07,\n",
       "   3.0709409770679486e-07,\n",
       "   1.1360067446730682e-06,\n",
       "   1.7648148968874011e-06,\n",
       "   1.7582998452780885e-06,\n",
       "   1.5831144537514774e-06,\n",
       "   1.838376647356199e-06,\n",
       "   2.2349147457134677e-06,\n",
       "   2.243330072815297e-06,\n",
       "   2.1186885987845017e-06,\n",
       "   2.312837523277267e-06,\n",
       "   2.532302914914908e-06,\n",
       "   2.3690445232205093e-06,\n",
       "   2.223844603577163e-06,\n",
       "   2.599239451228641e-06,\n",
       "   3.088900939474115e-06,\n",
       "   3.035644340343424e-06,\n",
       "   2.6228717615595087e-06,\n",
       "   2.400036237304448e-06,\n",
       "   2.265347575303167e-06,\n",
       "   1.8009956193054677e-06,\n",
       "   1.1436975455580978e-06,\n",
       "   7.516248388128588e-07,\n",
       "   7.15296380349173e-07,\n",
       "   8.849683581502177e-07,\n",
       "   1.212934876093641e-06,\n",
       "   1.4877867897666874e-06,\n",
       "   1.3104200888847117e-06,\n",
       "   7.779564157317509e-07,\n",
       "   5.467150003823917e-07,\n",
       "   8.138227940435172e-07,\n",
       "   9.567945653543575e-07,\n",
       "   5.875000397281838e-07,\n",
       "   1.6119199131026107e-07,\n",
       "   9.856918126160963e-08,\n",
       "   1.2726721365652338e-07,\n",
       "   -3.0819673924042945e-08,\n",
       "   -1.3591568404081045e-07,\n",
       "   -8.679985086246234e-08,\n",
       "   -2.7551902803679695e-07,\n",
       "   -7.771472496642673e-07,\n",
       "   -1.0099597602675203e-06,\n",
       "   -7.391026315417548e-07,\n",
       "   -5.943555834164727e-07,\n",
       "   -1.0310531024515512e-06,\n",
       "   -1.559963038744172e-06,\n",
       "   -1.573263602949737e-06,\n",
       "   -1.20922550195246e-06,\n",
       "   -9.016290505314828e-07,\n",
       "   -7.860601272113854e-07,\n",
       "   -9.509339520263893e-07,\n",
       "   -1.5454143067472614e-06,\n",
       "   -2.3064603738021106e-06,\n",
       "   -2.724058731473633e-06,\n",
       "   -2.8878439479740337e-06,\n",
       "   -3.2929387998592574e-06,\n",
       "   -3.758574166567996e-06,\n",
       "   -3.6046999412064906e-06,\n",
       "   -2.975662482640473e-06,\n",
       "   -2.758497657850967e-06,\n",
       "   -3.070137154281838e-06,\n",
       "   -3.1417948775924742e-06,\n",
       "   -2.80990093415312e-06,\n",
       "   -2.730590495048091e-06,\n",
       "   -2.9467480544553837e-06,\n",
       "   -2.774762606350123e-06,\n",
       "   -2.2380386326403823e-06,\n",
       "   -2.1263947473926237e-06,\n",
       "   -2.427431809337577e-06,\n",
       "   -2.182330945288413e-06,\n",
       "   -1.1459123925305903e-06,\n",
       "   -1.2347686606517527e-07,\n",
       "   3.7159799148867023e-07,\n",
       "   4.795015229319688e-07,\n",
       "   1.3322448921826435e-07,\n",
       "   -8.023095574571926e-07,\n",
       "   -1.8399470036456478e-06,\n",
       "   -2.6534203243500087e-06,\n",
       "   -3.889558229275281e-06,\n",
       "   -5.868411790288519e-06,\n",
       "   -7.371092124230927e-06,\n",
       "   -7.323998033825774e-06,\n",
       "   -6.6227757997694425e-06,\n",
       "   -6.494330591522157e-06,\n",
       "   -6.237202796910424e-06,\n",
       "   -4.6502004806825425e-06,\n",
       "   -2.5135771011264296e-06,\n",
       "   -1.4741492577741155e-06,\n",
       "   -1.5157858115344425e-06,\n",
       "   -1.6354501894966234e-06,\n",
       "   -1.9123592664982425e-06,\n",
       "   -2.872826371458359e-06,\n",
       "   -3.95034703615238e-06,\n",
       "   -4.415201146912295e-06,\n",
       "   -4.640896804630756e-06,\n",
       "   -4.942961822962388e-06,\n",
       "   -4.69562428406789e-06,\n",
       "   -3.7573877307295334e-06,\n",
       "   -3.2633624869049527e-06,\n",
       "   -3.588117806430091e-06,\n",
       "   -3.449683845246909e-06,\n",
       "   -2.50282255365164e-06,\n",
       "   -2.3311763470701408e-06,\n",
       "   -3.662691142380936e-06,\n",
       "   -5.0488738452258985e-06,\n",
       "   -5.503705324372277e-06,\n",
       "   -5.9362005231378134e-06,\n",
       "   -6.787164238630794e-06,\n",
       "   -6.966682576603489e-06,\n",
       "   -6.301752364379354e-06,\n",
       "   -6.311936431302456e-06,\n",
       "   -7.374660526693333e-06,\n",
       "   -7.803868356859311e-06,\n",
       "   -6.832440703874454e-06,\n",
       "   -5.7984816521639004e-06,\n",
       "   -5.578143372986233e-06,\n",
       "   -5.436999344965443e-06,\n",
       "   -5.0044350246025715e-06,\n",
       "   -4.821685251954477e-06,\n",
       "   -4.613821147358976e-06,\n",
       "   -3.59554269380169e-06,\n",
       "   -2.518927885830635e-06,\n",
       "   -2.8047547857568134e-06,\n",
       "   -4.031462594866753e-06,\n",
       "   -4.808094672625884e-06,\n",
       "   -5.44423619430745e-06,\n",
       "   -7.099784397723852e-06,\n",
       "   -9.11547067516949e-06,\n",
       "   -9.998855603043921e-06,\n",
       "   -1.0017375643656123e-05,\n",
       "   -1.0212655979557894e-05,\n",
       "   -9.979744390875567e-06,\n",
       "   -8.322359462908935e-06,\n",
       "   -6.300345376075711e-06,\n",
       "   -5.579151547863148e-06,\n",
       "   -5.719547061744379e-06,\n",
       "   -5.263697858026717e-06,\n",
       "   -4.376592187327333e-06,\n",
       "   -4.150499080424197e-06,\n",
       "   -4.5633532863575965e-06,\n",
       "   -5.004482773074415e-06,\n",
       "   -5.479371793626342e-06,\n",
       "   -5.858883923792746e-06,\n",
       "   -5.49387323189876e-06,\n",
       "   -4.60026967630256e-06,\n",
       "   -4.2364395085314754e-06,\n",
       "   -4.328894647187553e-06,\n",
       "   -3.8005694023013348e-06,\n",
       "   -2.962549842777662e-06,\n",
       "   -3.313871047794237e-06,\n",
       "   -4.754236215376295e-06,\n",
       "   -5.574270744546084e-06,\n",
       "   -5.460718966787681e-06,\n",
       "   -5.89114279136993e-06,\n",
       "   -7.293623639270663e-06,\n",
       "   -8.215529305743985e-06,\n",
       "   -7.660326446057297e-06,\n",
       "   -6.242593372007832e-06,\n",
       "   -4.8323827286367305e-06,\n",
       "   -3.7323388824006543e-06,\n",
       "   -3.0953924579080194e-06,\n",
       "   -2.774112772385706e-06,\n",
       "   -2.194703029090306e-06,\n",
       "   -1.4496814628728316e-06,\n",
       "   -1.6085521110653644e-06,\n",
       "   -2.9605407689814456e-06,\n",
       "   -4.258450644556433e-06,\n",
       "   -4.62922798760701e-06,\n",
       "   -4.636392986867577e-06,\n",
       "   -4.6178415686881635e-06,\n",
       "   -3.899445800925605e-06,\n",
       "   -2.5085503239097307e-06,\n",
       "   -1.6888131995074218e-06,\n",
       "   -2.000976110139163e-06,\n",
       "   -2.509618980184314e-06,\n",
       "   -2.56588168667804e-06,\n",
       "   -2.723940724536078e-06,\n",
       "   -3.523717396092252e-06,\n",
       "   -4.598161922331201e-06,\n",
       "   -5.161859007785097e-06,\n",
       "   -4.707742391474312e-06,\n",
       "   -3.378987003088696e-06,\n",
       "   -2.196307150370558e-06,\n",
       "   -2.0536983811325626e-06,\n",
       "   -2.362229224672774e-06,\n",
       "   -1.8533349930294207e-06,\n",
       "   -6.502728524537815e-07,\n",
       "   6.68283917093504e-08,\n",
       "   1.4647486068497528e-07,\n",
       "   3.144251365938544e-07,\n",
       "   3.5436653433862375e-07,\n",
       "   -3.6961239402444335e-07,\n",
       "   -1.143748477261397e-06,\n",
       "   -8.830337492327089e-07,\n",
       "   -5.432460881138468e-08,\n",
       "   2.4773916607045976e-07,\n",
       "   9.814898760396318e-08,\n",
       "   -1.254988717391825e-07,\n",
       "   -6.309863351816603e-07,\n",
       "   -9.872127293419908e-07,\n",
       "   -4.86457395254547e-07,\n",
       "   -3.908064627466956e-07,\n",
       "   -2.409439275652403e-06,\n",
       "   -4.7161120164673775e-06,\n",
       "   -4.045597052027006e-06,\n",
       "   -1.2628418062377023e-06,\n",
       "   2.3699200824012223e-07,\n",
       "   7.164534849835036e-07,\n",
       "   2.560754865044146e-06,\n",
       "   4.097264536540024e-06,\n",
       "   2.3005743514659116e-06,\n",
       "   -6.024372396495892e-07,\n",
       "   -7.603849212500791e-07,\n",
       "   -1.939955183161146e-07,\n",
       "   -2.5393708256160608e-06,\n",
       "   -5.158258318260778e-06,\n",
       "   -4.232216724631144e-06,\n",
       "   -2.6536449695413467e-06,\n",
       "   -3.972812010033522e-06,\n",
       "   -4.712796908279415e-06,\n",
       "   -1.8364926290814765e-06,\n",
       "   2.646658288085746e-07,\n",
       "   -1.0928769142992678e-06,\n",
       "   -1.1828556125692558e-06,\n",
       "   6.430436769733205e-07,\n",
       "   -2.444458004902117e-06,\n",
       "   -9.041490557137877e-06,\n",
       "   -8.2772494351957e-06,\n",
       "   -1.9747635633393656e-06,\n",
       "   -5.216174031374976e-06,\n",
       "   -1.6384783521061763e-05,\n",
       "   -1.4754552466911264e-05,\n",
       "   2.2491321942652576e-06,\n",
       "   1.1445072232163511e-05,\n",
       "   4.894368430541363e-06,\n",
       "   2.0172806216578465e-06,\n",
       "   8.607613381172996e-06,\n",
       "   4.6964760258561e-06,\n",
       "   -1.2296996828808915e-05,\n",
       "   -1.562541729072109e-05,\n",
       "   3.492985342745669e-06,\n",
       "   1.871997483249288e-05,\n",
       "   7.153063052101061e-06,\n",
       "   -3.9245096559170634e-05,\n",
       "   -0.0001325219782302156,\n",
       "   -0.0002518248511478305,\n",
       "   -0.0002968877088278532,\n",
       "   -0.0001723240129649639,\n",
       "   7.064482633722946e-05,\n",
       "   0.0002712217392399907,\n",
       "   0.00035384169314056635,\n",
       "   0.0003894426627084613,\n",
       "   0.0004527238488662988,\n",
       "   0.00053539959480986,\n",
       "   0.0006239003269001842,\n",
       "   0.000736686575692147,\n",
       "   0.0008460143581032753,\n",
       "   0.0008861722890287638,\n",
       "   0.0008811891311779618,\n",
       "   0.0009407312609255314,\n",
       "   0.0010873139835894108,\n",
       "   0.0012127186637371778,\n",
       "   0.001242246595211327,\n",
       "   0.0012076772982254624,\n",
       "   0.0011240743333473802,\n",
       "   0.0009483826579526067,\n",
       "   0.0007081293151713908,\n",
       "   0.0005149102071300149,\n",
       "   0.00039499797276221216,\n",
       "   0.0002587204799056053,\n",
       "   8.479413372697309e-05,\n",
       "   -3.2940490200417116e-05,\n",
       "   -7.513442687923089e-05,\n",
       "   -0.00015494100807700306,\n",
       "   -0.00031873356783762574,\n",
       "   -0.0004613639903254807,\n",
       "   -0.0005097968969494104,\n",
       "   -0.0005216694553382695,\n",
       "   -0.0005390909500420094,\n",
       "   -0.0005242051556706429,\n",
       "   -0.0005063462303951383,\n",
       "   -0.0006028193747624755,\n",
       "   -0.0008108731126412749,\n",
       "   -0.0009605811210349202,\n",
       "   -0.0009602175559848547,\n",
       "   -0.000917653611395508,\n",
       "   -0.0009433999075554311,\n",
       "   -0.001010379521176219,\n",
       "   -0.0010840948671102524,\n",
       "   -0.0012089202646166086,\n",
       "   -0.0013778253924101591,\n",
       "   -0.0014839235227555037,\n",
       "   -0.0014821174554526806,\n",
       "   -0.0014433467295020819,\n",
       "   -0.0013912254944443703,\n",
       "   -0.0012586602242663503,\n",
       "   -0.001063058851286769,\n",
       "   -0.0009385772282257676,\n",
       "   -0.0009214414749294519,\n",
       "   -0.0008810987928882241,\n",
       "   -0.0007421329501084983,\n",
       "   -0.0006040600128471851,\n",
       "   -0.0005581810837611556,\n",
       "   -0.000539668370038271,\n",
       "   -0.0004479498602449894,\n",
       "   -0.000288558192551136,\n",
       "   -0.00012843818694818765,\n",
       "   -1.5651137800887227e-05,\n",
       "   2.3900787709862925e-05,\n",
       "   1.7793656297726557e-05,\n",
       "   8.097897080006078e-05,\n",
       "   0.0002954969822894782,\n",
       "   0.0005617168499156833,\n",
       "   0.0007043926743790507,\n",
       "   0.0007160968380048871,\n",
       "   0.0007472370052710176,\n",
       "   0.0008637203136458993,\n",
       "   0.0009737382642924786,\n",
       "   0.001005580648779869,\n",
       "   0.0010085857938975096,\n",
       "   0.0010513786692172289,\n",
       "   0.0011397262569516897,\n",
       "   0.0012495556147769094,\n",
       "   0.0013424735516309738,\n",
       "   0.0013523803791031241,\n",
       "   0.0012500310549512506,\n",
       "   0.0011056349612772465,\n",
       "   0.0010063534136861563,\n",
       "   0.0009446066105738282,\n",
       "   0.0008622236200608313,\n",
       "   0.0007498797494918108,\n",
       "   0.0006163467769511044,\n",
       "   0.00042279064655303955,\n",
       "   0.00014432391617447138,\n",
       "   -0.00015137906302697957,\n",
       "   -0.00036997225834056735,\n",
       "   -0.0004910118877887726,\n",
       "   -0.0005478090024553239,\n",
       "   -0.0005736174643971026,\n",
       "   -0.0006151061388663948,\n",
       "   -0.0007184225833043456,\n",
       "   -0.000850495882332325,\n",
       "   -0.0009156133164651692,\n",
       "   -0.0008888310985639691,\n",
       "   -0.000843080400954932,\n",
       "   -0.0008226054487749934,\n",
       "   -0.0008006145944818854,\n",
       "   -0.0007823477499186993,\n",
       "   -0.000818124448414892,\n",
       "   -0.0008827643468976021,\n",
       "   -0.000877995858900249,\n",
       "   -0.0007919360650703311,\n",
       "   -0.0007264702580869198,\n",
       "   -0.000739302602596581,\n",
       "   -0.000791452475823462,\n",
       "   -0.0008648865623399615,\n",
       "   -0.000983883859589696,\n",
       "   -0.0011047087609767914,\n",
       "   -0.0011447659926488996,\n",
       "   -0.0011416689958423376,\n",
       "   -0.0012192294234409928,\n",
       "   -0.001374602084979415,\n",
       "   -0.0014671984827145934,\n",
       "   -0.001439157989807427,\n",
       "   -0.0013725175522267818,\n",
       "   -0.0013059743214398623,\n",
       "   -0.0011859764344990253,\n",
       "   -0.0010436634765937924,\n",
       "   -0.0010240939445793629,\n",
       "   -0.0011618982534855604,\n",
       "   -0.0012880819849669933,\n",
       "   -0.0012444952735677361,\n",
       "   -0.0010670132469385862,\n",
       "   -0.0008913702913559973,\n",
       "   -0.0007909383857622743,\n",
       "   -0.0007587102008983493,\n",
       "   -0.0007452272693626583,\n",
       "   -0.0006720233941450715,\n",
       "   -0.0004991869209334254,\n",
       "   -0.00029804304358549416,\n",
       "   -0.0001643152500037104,\n",
       "   -6.305763963609934e-05,\n",
       "   0.0001248140906682238,\n",
       "   0.00040175742469727993,\n",
       "   0.0006363099091686308,\n",
       "   0.0007693130755797029,\n",
       "   0.000900760293006897,\n",
       "   0.0011145186144858599,\n",
       "   0.001328016398474574,\n",
       "   0.0013997675850987434,\n",
       "   0.0013231838820502162,\n",
       "   0.0012403397122398019,\n",
       "   0.0012839981354773045,\n",
       "   0.0014488489832729101,\n",
       "   0.0016122099477797747,\n",
       "   0.0016608941368758678,\n",
       "   0.0015950938686728477,\n",
       "   0.001506850472651422,\n",
       "   0.001465515815652907,\n",
       "   0.0014500009128823876,\n",
       "   0.0013980179792270064,\n",
       "   0.0012882057344540954,\n",
       "   0.0011564388405531645,\n",
       "   0.0010518701747059822,\n",
       "   0.0009904381586238742,\n",
       "   0.0009431095095351338,\n",
       "   0.000875891069881618,\n",
       "   0.0008068041643127799,\n",
       "   0.0007878592004999518,\n",
       "   0.0008090756018646061,\n",
       "   0.0007726547191850841,\n",
       "   0.0006125420331954956,\n",
       "   0.00039160955930128694,\n",
       "   0.00021815174841322005,\n",
       "   0.00011316748714307323,\n",
       "   3.169586125295609e-05,\n",
       "   -3.394792656763457e-05,\n",
       "   -6.295675120782107e-05,\n",
       "   -8.057360537350178e-05,\n",
       "   -0.00012920194421894848,\n",
       "   -0.00018761976389214396,\n",
       "   -0.0002055745862890035,\n",
       "   -0.00019597513892222196,\n",
       "   -0.00021024409215897322,\n",
       "   -0.0002455689827911556,\n",
       "   -0.00025894970167428255,\n",
       "   -0.0002534321101848036,\n",
       "   -0.0002657596778590232,\n",
       "   -0.0002885031281039119,\n",
       "   -0.0002849313314072788,\n",
       "   -0.00026481255190446973,\n",
       "   -0.0002681900514289737,\n",
       "   -0.0002887207083404064,\n",
       "   -0.00028754823142662644,\n",
       "   -0.00026771827833727,\n",
       "   -0.0002646106877364218,\n",
       "   -0.0002766655234154314,\n",
       "   -0.0002722134522628039,\n",
       "   -0.0002523540169931948,\n",
       "   -0.00024661788484081626,\n",
       "   -0.00025600779918022454,\n",
       "   -0.0002558420819696039,\n",
       "   -0.00024295850016642362,\n",
       "   -0.0002340662176720798,\n",
       "   -0.00023027686984278262,\n",
       "   -0.00022272983915172517,\n",
       "   -0.000216341795749031,\n",
       "   -0.00021494796965271235,\n",
       "   -0.00020489699090830982,\n",
       "   -0.00018164326320402324,\n",
       "   -0.00016689737094566226,\n",
       "   -0.00016917940229177475,\n",
       "   -0.00016154641343746334,\n",
       "   -0.00012755616626236588,\n",
       "   -9.4452771008946e-05,\n",
       "   -8.85134722921066e-05,\n",
       "   -9.19222438824363e-05,\n",
       "   -7.731854566372931e-05,\n",
       "   -5.403402974479832e-05,\n",
       "   -4.60139344795607e-05,\n",
       "   -4.9240356020163745e-05,\n",
       "   -4.411057670949958e-05,\n",
       "   -2.8277812816668302e-05,\n",
       "   -1.3356077033677138e-05,\n",
       "   -5.4923671086726245e-06,\n",
       "   -6.527740879391786e-06,\n",
       "   -1.65467536135111e-05,\n",
       "   -2.350477734580636e-05,\n",
       "   -1.2041008631058503e-05,\n",
       "   9.476991181145422e-06,\n",
       "   1.4890762940922286e-05,\n",
       "   -8.995152711577248e-07,\n",
       "   -1.4633979844802525e-05,\n",
       "   -1.2388916729833e-05,\n",
       "   -7.412662398564862e-06,\n",
       "   -1.3504708476830274e-05,\n",
       "   -2.551635952841025e-05,\n",
       "   -3.470298179308884e-05,\n",
       "   -4.093161260243505e-05,\n",
       "   -4.272969817975536e-05,\n",
       "   -3.60443809768185e-05,\n",
       "   -2.6150522899115458e-05,\n",
       "   -2.3028354917187244e-05,\n",
       "   -2.2007552615832537e-05,\n",
       "   -1.088394765247358e-05,\n",
       "   5.76416732656071e-06,\n",
       "   9.672410669736564e-06,\n",
       "   -1.9208303001505556e-06,\n",
       "   -1.0894322258536704e-05,\n",
       "   -6.212748758116504e-06,\n",
       "   1.9739309209398925e-06,\n",
       "   1.24237624277157e-06,\n",
       "   -5.039416009822162e-06,\n",
       "   -6.049647709005512e-06,\n",
       "   1.988248641282553e-06,\n",
       "   1.2896429325337522e-05,\n",
       "   1.7749702237779275e-05,\n",
       "   1.2860680726589635e-05,\n",
       "   3.880961230606772e-06,\n",
       "   -9.111512326853699e-07,\n",
       "   -2.3690447505941847e-06,\n",
       "   -1.0020296031143516e-05,\n",
       "   -2.6243309548590332e-05,\n",
       "   -4.0660612285137177e-05,\n",
       "   -4.4957072532270104e-05,\n",
       "   -4.339642691775225e-05,\n",
       "   -4.326905036577955e-05,\n",
       "   -4.333285323809832e-05,\n",
       "   -4.07532716053538e-05,\n",
       "   -3.901200398104265e-05,\n",
       "   -4.078017809661105e-05,\n",
       "   -3.951753387809731e-05,\n",
       "   -2.9793140129186213e-05,\n",
       "   -1.870043524831999e-05,\n",
       "   -1.6758391211624257e-05,\n",
       "   -2.2145643015392125e-05,\n",
       "   -2.3615750251337886e-05,\n",
       "   -1.6911026250454597e-05,\n",
       "   -8.226933459809516e-06,\n",
       "   -3.1612707971362397e-06,\n",
       "   -4.6563221189899195e-07,\n",
       "   1.7982904410018818e-06,\n",
       "   2.912174750235863e-06,\n",
       "   2.646770099090645e-06,\n",
       "   ...],\n",
       "  'path': 'C:\\\\Users\\\\T H E J\\\\Desktop\\\\Badaga_Corpus-v.0.1.0\\\\clips\\\\F002_1_1.mp3',\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': 'MANAYA AENA UDHAKA '}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataset after removing special characters\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26efc5-fe32-480d-845b-7273ee1d288b",
   "metadata": {},
   "source": [
    "###  Vocabulary File for CTC Tokenizer\n",
    "\n",
    "We have created a JSON vocabulary file (`stt-vocab.json`) for use with the `Wav2Vec2CTCTokenizer`.  \n",
    "This file maps each character or token to a unique integer ID. Here's a breakdown of its contents:\n",
    "\n",
    "---\n",
    "\n",
    "###  Character-Level Vocabulary (For CTC)\n",
    "\n",
    "The vocabulary includes:\n",
    "\n",
    "#### 1. **Special Tokens (for CTC and Transformers)**\n",
    "| Token     | Description                                                                 |\n",
    "|-----------|-----------------------------------------------------------------------------|\n",
    "| `<pad>`   | Padding token — used to align sequences of varying lengths.                 |\n",
    "| `<s>`     | Start of sentence — often required for seq2seq models (not used in CTC).    |\n",
    "| `</s>`    | End of sentence — same as above, reserved but not always used.              |\n",
    "| `<unk>`   | Unknown token — used when the model encounters an unseen character.         |\n",
    "| `|`       | Word delimiter token — replaces whitespace between words.                   |\n",
    "\n",
    "#### 2. **Punctuation/Other Symbols**\n",
    "| Symbol | Use Case                        |\n",
    "|--------|----------------------------------|\n",
    "| `'`    | Apostrophe in contractions.     |\n",
    "| `-`    | Hyphen in compound words.       |\n",
    "\n",
    "#### 3. **Uppercase Letters A-Z**\n",
    "- Each letter from `A` to `Z` is treated as a **distinct token**.\n",
    "- The model will output these characters during inference.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"<pad>\": 0,\n",
    "  \"<s>\": 1,\n",
    "  \"</s>\": 2,\n",
    "  \"<unk>\": 3,\n",
    "  \"|\": 4,\n",
    "  \"'\": 5,\n",
    "  \"-\": 6,\n",
    "  \"A\": 7,\n",
    "  \"B\": 8,\n",
    "  ...\n",
    "  \"Z\": 32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156b053-6e41-4b8d-8450-2175f5a6e6b2",
   "metadata": {},
   "source": [
    "### Initializing the Wav2Vec2 CTC Tokenizer\n",
    "\n",
    "We initialize the `Wav2Vec2CTCTokenizer` with a custom vocabulary JSON file for CTC-based speech recognition.  \n",
    "Special tokens like `<unk>`, `<pad>`, and `|` are defined for unknown characters, padding, and word separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0165eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "vocab_file = r\"C:\\Users\\T H E J\\Desktop\\Badaga_Corpus-v.0.1.0\\stt-vocab.json\"\n",
    "tokenizer = Wav2Vec2CTCTokenizer(vocab_file, unk_token=\"<unk>\", pad_token=\"<pad>\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c102c-1f20-49a6-bc32-f14dfb711d6d",
   "metadata": {},
   "source": [
    "### Creating `Wav2Vec2FeatureExtractor`\n",
    "\n",
    "The `Wav2Vec2FeatureExtractor` is used to preprocess raw audio input for the Wav2Vec2 model.\n",
    "\n",
    "- `feature_size=1`: Wav2Vec2 expects a single feature from raw audio.\n",
    "- `sampling_rate=16000`: The audio sampling rate used during training.\n",
    "- `padding_value=0.0`: Used to pad shorter audio sequences for batching.\n",
    "- `do_normalize=True`: Normalizes the audio for better model performance.\n",
    "- `return_attention_mask=True`: Enables attention masking, especially needed for XLS-R models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e219416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the feature extractor for feature extraction\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350055bf-bbb2-4568-a6d2-ebe19ffce2d9",
   "metadata": {},
   "source": [
    "### Using `Wav2Vec2Processor`\n",
    "\n",
    "* The `Wav2Vec2Processor` combines both the tokenizer and feature extractor into a single class.  \n",
    "* This simplifies training and inference by allowing you to use just the `processor` along with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a477df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the processor which takes the tokenizer and feature extractor to process\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a096a04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 0,\n",
       " 'audio': {'array': [-4.381633131409629e-13,\n",
       "   -4.547211402989443e-13,\n",
       "   -3.9910945642124274e-13,\n",
       "   -3.477597441785274e-13,\n",
       "   -5.892689764960823e-13,\n",
       "   -7.35186759560913e-13,\n",
       "   -1.9754379067867672e-13,\n",
       "   -6.340125906917349e-13,\n",
       "   -3.9618181239993444e-13,\n",
       "   1.3508462469273563e-13,\n",
       "   -3.499395326463095e-14,\n",
       "   -4.2430406519029795e-13,\n",
       "   1.7334330043410062e-13,\n",
       "   -4.451782367222157e-13,\n",
       "   -1.756699440861459e-13,\n",
       "   -4.5253256979356504e-13,\n",
       "   -8.702850723060762e-13,\n",
       "   1.7466076870399638e-14,\n",
       "   1.5608089094180239e-13,\n",
       "   -5.420372267347928e-13,\n",
       "   -3.7012819024961896e-13,\n",
       "   3.2685109501752463e-13,\n",
       "   -6.801431976215938e-14,\n",
       "   -3.582878893744479e-13,\n",
       "   -1.0914449140482507e-13,\n",
       "   -3.098158936429979e-13,\n",
       "   -4.894797132719286e-13,\n",
       "   -6.201866277477652e-13,\n",
       "   -9.631275811605722e-13,\n",
       "   -1.0823816615126297e-13,\n",
       "   -4.2352512013947574e-13,\n",
       "   -6.471780576722264e-13,\n",
       "   -7.760326127363715e-14,\n",
       "   3.445004698177101e-13,\n",
       "   -4.1060592968246434e-13,\n",
       "   -9.60529670124971e-14,\n",
       "   -1.017909647088415e-14,\n",
       "   2.0151568402241443e-13,\n",
       "   -1.8473360319758159e-13,\n",
       "   -4.788004845032723e-13,\n",
       "   6.292361786784315e-14,\n",
       "   1.0348785122306445e-14,\n",
       "   -5.286402825904757e-13,\n",
       "   -3.518745082635444e-13,\n",
       "   -5.910927265229474e-14,\n",
       "   -1.4359487991028042e-13,\n",
       "   -4.368519435082874e-13,\n",
       "   -1.5826226505526175e-13,\n",
       "   4.559846424057046e-13,\n",
       "   -1.9462357344224995e-14,\n",
       "   5.740050904208538e-15,\n",
       "   -4.074549129085697e-13,\n",
       "   9.46933097255645e-14,\n",
       "   2.356149129967289e-13,\n",
       "   -4.911019507725101e-13,\n",
       "   1.8375099076865797e-13,\n",
       "   9.639137361558414e-13,\n",
       "   -4.53415869303489e-13,\n",
       "   -8.386903367976761e-13,\n",
       "   3.0472450734606027e-13,\n",
       "   1.993705493665704e-15,\n",
       "   -7.838418499342414e-13,\n",
       "   8.7484503690817e-14,\n",
       "   2.941383573339118e-13,\n",
       "   2.5216046156510685e-13,\n",
       "   -1.408297577946277e-13,\n",
       "   -4.3263542704938263e-13,\n",
       "   5.190375039487716e-13,\n",
       "   -3.2847593460332003e-13,\n",
       "   -1.016547956922409e-12,\n",
       "   -7.45627247011188e-13,\n",
       "   3.075170868817312e-13,\n",
       "   -3.8260105532979954e-14,\n",
       "   -5.608961103735488e-13,\n",
       "   2.830118951691052e-13,\n",
       "   7.077655518952786e-13,\n",
       "   1.090673992093505e-12,\n",
       "   -5.932434448199797e-14,\n",
       "   -5.400598046025051e-13,\n",
       "   1.1895084526744593e-12,\n",
       "   -9.342125597416873e-13,\n",
       "   -2.2508047942820797e-12,\n",
       "   1.1689608699419485e-12,\n",
       "   5.006984952517224e-13,\n",
       "   -2.32021823629025e-12,\n",
       "   8.685459036011922e-13,\n",
       "   4.2685043867563e-12,\n",
       "   3.0379184953223393e-13,\n",
       "   -1.8080820044300006e-12,\n",
       "   -8.684166124921233e-13,\n",
       "   -8.30207755840584e-13,\n",
       "   -2.884028519473114e-12,\n",
       "   -4.902856766408892e-12,\n",
       "   -2.428373040846976e-12,\n",
       "   -1.962378827144451e-12,\n",
       "   -7.491035569628934e-12,\n",
       "   -4.041347118066696e-12,\n",
       "   1.590015120435384e-12,\n",
       "   -1.7332828965502256e-12,\n",
       "   3.5130882578005007e-12,\n",
       "   3.049642136043751e-12,\n",
       "   -3.1388997304149235e-12,\n",
       "   3.4116182101584513e-12,\n",
       "   -3.507852103408482e-13,\n",
       "   -9.877114751088989e-12,\n",
       "   3.0780105027272686e-12,\n",
       "   4.514749685213815e-12,\n",
       "   -1.2407554150772881e-11,\n",
       "   5.783984402540909e-12,\n",
       "   3.0355263441750324e-11,\n",
       "   3.1092840975521785e-12,\n",
       "   7.637098418944444e-14,\n",
       "   5.842808008249545e-12,\n",
       "   -1.7768829810305142e-11,\n",
       "   -2.6743369671566875e-11,\n",
       "   -2.0839904454894587e-11,\n",
       "   -1.4400433102912391e-11,\n",
       "   -1.9889159763586406e-11,\n",
       "   -2.127594801726307e-11,\n",
       "   -1.2708419386275871e-11,\n",
       "   -1.0224760274568645e-11,\n",
       "   -2.1962640039951964e-13,\n",
       "   5.3149290524245885e-11,\n",
       "   4.233953812549096e-11,\n",
       "   -1.925149276105209e-11,\n",
       "   -2.6993674656639044e-11,\n",
       "   -8.215703291292176e-12,\n",
       "   -1.4231900380412554e-11,\n",
       "   -2.568116205803328e-11,\n",
       "   -1.309875471977584e-11,\n",
       "   -1.634295476726777e-11,\n",
       "   -4.1149050312994095e-12,\n",
       "   2.704641892392612e-11,\n",
       "   2.811519420053976e-11,\n",
       "   9.595593417066617e-12,\n",
       "   -3.835613424096884e-11,\n",
       "   -6.831529786310853e-11,\n",
       "   -5.257390876811652e-12,\n",
       "   5.8184800727500985e-11,\n",
       "   2.5434201619822794e-11,\n",
       "   -1.2714693013726741e-11,\n",
       "   -6.525988083261325e-12,\n",
       "   -1.501309840334919e-11,\n",
       "   2.9581056354421875e-11,\n",
       "   7.440570382044598e-11,\n",
       "   7.853648981148709e-11,\n",
       "   8.288236763576151e-11,\n",
       "   2.511636211510737e-11,\n",
       "   1.1371530453385681e-11,\n",
       "   4.8503152882961587e-11,\n",
       "   3.8887365549911124e-11,\n",
       "   2.4479553800693665e-11,\n",
       "   3.595799699662727e-11,\n",
       "   7.889890130119426e-11,\n",
       "   4.066968636862178e-11,\n",
       "   -6.279218811577891e-11,\n",
       "   -1.1824705103968824e-10,\n",
       "   -1.1622879741990388e-10,\n",
       "   -6.62555565966727e-11,\n",
       "   -3.2908460678715556e-11,\n",
       "   2.9796189821018615e-11,\n",
       "   8.054504285759378e-11,\n",
       "   9.220803287579571e-11,\n",
       "   1.1214966455508346e-10,\n",
       "   9.186676419581374e-11,\n",
       "   6.231793553412857e-11,\n",
       "   8.945134910565145e-11,\n",
       "   6.992913192949146e-11,\n",
       "   2.148869623908034e-11,\n",
       "   4.298046293871316e-11,\n",
       "   4.5057221842448314e-11,\n",
       "   7.67954103086943e-11,\n",
       "   1.1495081275736396e-10,\n",
       "   1.3176648661072932e-10,\n",
       "   5.295661478776914e-11,\n",
       "   -3.647595767097833e-11,\n",
       "   -1.2618039425815741e-11,\n",
       "   1.3835164784647969e-11,\n",
       "   -3.635711523508611e-11,\n",
       "   -6.750836695212925e-11,\n",
       "   -1.60435466994846e-11,\n",
       "   3.440896526041293e-11,\n",
       "   1.8296596876465898e-11,\n",
       "   -2.4884979493711157e-11,\n",
       "   6.183745876464641e-11,\n",
       "   7.609166075006613e-11,\n",
       "   4.7237422307055965e-11,\n",
       "   4.027559188934937e-11,\n",
       "   9.467734235490965e-11,\n",
       "   1.1961404089433358e-10,\n",
       "   1.0087189417085085e-10,\n",
       "   6.451278400376736e-11,\n",
       "   6.062051555177916e-11,\n",
       "   1.0736717070969348e-10,\n",
       "   8.231806208902626e-11,\n",
       "   2.103562463107167e-11,\n",
       "   -2.839358262396452e-11,\n",
       "   6.817512700207917e-12,\n",
       "   1.0827622652642699e-11,\n",
       "   6.750972003644051e-11,\n",
       "   -5.3158203533465453e-11,\n",
       "   -7.030930698759263e-11,\n",
       "   6.144476594194259e-11,\n",
       "   1.9187032518352964e-10,\n",
       "   1.886563683051179e-10,\n",
       "   -3.463182865481862e-11,\n",
       "   -2.0809269585253531e-10,\n",
       "   -2.015883848738298e-10,\n",
       "   -6.957961984355165e-11,\n",
       "   -2.679022802209996e-12,\n",
       "   -1.4276101134580443e-11,\n",
       "   -2.0165455416609745e-10,\n",
       "   -3.4962954753581243e-10,\n",
       "   -3.040288298894467e-10,\n",
       "   -5.836366112621505e-11,\n",
       "   5.4852549585815424e-11,\n",
       "   3.8911717598066886e-11,\n",
       "   -1.365095814165329e-10,\n",
       "   -1.4276746451713507e-10,\n",
       "   -5.528327101655961e-11,\n",
       "   -8.729841849408615e-11,\n",
       "   -9.537061418374293e-11,\n",
       "   -1.762320983589305e-10,\n",
       "   -1.7491333381691732e-10,\n",
       "   -1.1365150487385733e-10,\n",
       "   -3.616557400776266e-11,\n",
       "   -8.292305037072012e-11,\n",
       "   -8.795889711032956e-11,\n",
       "   -6.424157733553315e-11,\n",
       "   2.7931152182802954e-11,\n",
       "   5.585548343289837e-11,\n",
       "   7.006905472506375e-12,\n",
       "   -1.0805195280183533e-11,\n",
       "   7.119833889124294e-11,\n",
       "   7.44357492310499e-11,\n",
       "   -3.783275082103188e-11,\n",
       "   1.797863420638368e-11,\n",
       "   6.124735441037643e-11,\n",
       "   1.5053971957890155e-11,\n",
       "   -1.1606937633246162e-10,\n",
       "   -1.3212246574578757e-10,\n",
       "   -7.575184229891008e-11,\n",
       "   -1.5690454491235073e-10,\n",
       "   -3.025191208649858e-10,\n",
       "   -2.271112742313619e-10,\n",
       "   -6.957676101926324e-11,\n",
       "   -7.287659191390627e-12,\n",
       "   -3.109433890924329e-11,\n",
       "   -3.4931224579537457e-11,\n",
       "   -3.307545903830089e-11,\n",
       "   -1.0011752538119367e-10,\n",
       "   -1.4149435963173307e-11,\n",
       "   4.1435695152802765e-11,\n",
       "   3.1329976807326076e-11,\n",
       "   8.16067005637855e-11,\n",
       "   1.385584424973274e-10,\n",
       "   1.9218981961444115e-10,\n",
       "   2.9518559818697554e-10,\n",
       "   2.8559674070116614e-10,\n",
       "   2.328346959679095e-10,\n",
       "   1.4463966135913608e-10,\n",
       "   -5.2941651063065365e-11,\n",
       "   -2.628095796541885e-10,\n",
       "   -3.530582215471867e-10,\n",
       "   -1.433125701444382e-10,\n",
       "   -4.869262978934863e-12,\n",
       "   -6.646105193963692e-11,\n",
       "   -1.1014060496972178e-10,\n",
       "   -4.6540268167083454e-11,\n",
       "   7.904571094896617e-12,\n",
       "   -1.5789974883162472e-10,\n",
       "   -1.565677865134063e-10,\n",
       "   3.0088879304779326e-11,\n",
       "   1.4380523161161562e-10,\n",
       "   3.0376612336624476e-10,\n",
       "   2.756689321259387e-10,\n",
       "   2.5011850923739587e-10,\n",
       "   1.9509414916907275e-10,\n",
       "   1.7744375413464297e-11,\n",
       "   1.5799646313485738e-10,\n",
       "   4.3786663184164354e-10,\n",
       "   3.104929924280242e-10,\n",
       "   1.2796279660887144e-11,\n",
       "   -5.52405378384524e-11,\n",
       "   2.928509518218547e-11,\n",
       "   8.45195718968128e-11,\n",
       "   1.0132890360114999e-10,\n",
       "   8.247472149669477e-11,\n",
       "   1.095268806206029e-10,\n",
       "   7.617672465043412e-11,\n",
       "   -1.8980851612671046e-11,\n",
       "   6.575288924448586e-11,\n",
       "   2.5063010694603705e-11,\n",
       "   -2.0881124607186052e-10,\n",
       "   -3.243830759558364e-10,\n",
       "   7.31118221519722e-11,\n",
       "   3.511189672344983e-10,\n",
       "   2.6178426093537155e-10,\n",
       "   2.0051033056134315e-10,\n",
       "   2.6012658693730373e-10,\n",
       "   2.810684462950519e-10,\n",
       "   2.888013161950198e-10,\n",
       "   2.2466101201601418e-10,\n",
       "   1.5745317549775706e-10,\n",
       "   9.038207682277033e-11,\n",
       "   -1.17232584750937e-10,\n",
       "   -1.1168387048510198e-10,\n",
       "   -6.424489412681922e-11,\n",
       "   -9.140840168120334e-11,\n",
       "   -1.4000441084238702e-10,\n",
       "   -1.4406664750055143e-10,\n",
       "   -1.078076239391379e-10,\n",
       "   -6.5457556909509496e-12,\n",
       "   -2.118559841446377e-11,\n",
       "   -9.97382315626183e-11,\n",
       "   -1.1240765263043073e-10,\n",
       "   -1.2121016690347375e-10,\n",
       "   -1.2838206886467418e-10,\n",
       "   2.2543845262790185e-11,\n",
       "   2.8913385574647066e-11,\n",
       "   -3.749414320686206e-11,\n",
       "   -6.401570940006707e-11,\n",
       "   8.82271339319729e-12,\n",
       "   1.8738760543257627e-10,\n",
       "   2.4690705036078953e-10,\n",
       "   2.4435725665128416e-10,\n",
       "   2.131194110077672e-10,\n",
       "   6.575226474403451e-13,\n",
       "   -9.972714321015985e-11,\n",
       "   3.7643551470400993e-11,\n",
       "   -7.071133956149112e-11,\n",
       "   -1.366514401635044e-10,\n",
       "   -2.7063899732393537e-11,\n",
       "   -4.687795290836405e-11,\n",
       "   -1.1377569719694947e-10,\n",
       "   -5.016834170312734e-12,\n",
       "   8.694290426491946e-11,\n",
       "   3.735144485372821e-11,\n",
       "   -5.694201360428863e-11,\n",
       "   1.36202174538802e-10,\n",
       "   -7.478655195125583e-11,\n",
       "   -1.7989415512786877e-10,\n",
       "   1.4084655663992862e-10,\n",
       "   1.858155052048005e-08,\n",
       "   6.046862210951076e-08,\n",
       "   7.319491146517976e-08,\n",
       "   3.586593066984278e-08,\n",
       "   1.0682358997371466e-08,\n",
       "   2.875271931657153e-08,\n",
       "   4.067840819743651e-08,\n",
       "   2.1935345984047672e-08,\n",
       "   8.128162587439647e-10,\n",
       "   -1.3067962711943437e-08,\n",
       "   -1.6273450142989532e-08,\n",
       "   1.9676527074352634e-08,\n",
       "   7.42545438470188e-08,\n",
       "   6.694107668181459e-08,\n",
       "   -1.758702738996476e-09,\n",
       "   -3.8566490445646195e-08,\n",
       "   -2.110973973401542e-08,\n",
       "   -9.933319944366303e-09,\n",
       "   9.150141089264707e-09,\n",
       "   1.0129067362640853e-07,\n",
       "   2.122872331256076e-07,\n",
       "   2.3227822509852558e-07,\n",
       "   2.048021769951447e-07,\n",
       "   2.73481788326535e-07,\n",
       "   4.521891696640523e-07,\n",
       "   6.115581641097378e-07,\n",
       "   6.48633829314349e-07,\n",
       "   5.649122840623022e-07,\n",
       "   4.376271931505471e-07,\n",
       "   3.663415668597736e-07,\n",
       "   3.69095317864776e-07,\n",
       "   3.4718163988145534e-07,\n",
       "   2.68892620169936e-07,\n",
       "   2.8365656135065365e-07,\n",
       "   4.858029001297837e-07,\n",
       "   7.168181923589145e-07,\n",
       "   8.059061542553536e-07,\n",
       "   8.140432328218594e-07,\n",
       "   8.228115575548145e-07,\n",
       "   7.254727734107291e-07,\n",
       "   4.7564731175953057e-07,\n",
       "   2.8606675073206134e-07,\n",
       "   3.270848765168921e-07,\n",
       "   4.809682536688342e-07,\n",
       "   5.913254312872596e-07,\n",
       "   6.993186048021016e-07,\n",
       "   8.907123856261023e-07,\n",
       "   1.1692836778820492e-06,\n",
       "   1.5303969576052623e-06,\n",
       "   1.88132980838418e-06,\n",
       "   1.960940153367119e-06,\n",
       "   1.6879805571079487e-06,\n",
       "   1.4121999356575543e-06,\n",
       "   1.412335677741794e-06,\n",
       "   1.4233761476134532e-06,\n",
       "   1.140323774961871e-06,\n",
       "   8.34552338346839e-07,\n",
       "   8.954414170148084e-07,\n",
       "   1.1451458021838334e-06,\n",
       "   1.2204836821183562e-06,\n",
       "   1.2412403975758934e-06,\n",
       "   1.4784229733777465e-06,\n",
       "   1.760135319273104e-06,\n",
       "   1.7923865698321606e-06,\n",
       "   1.6666419924149523e-06,\n",
       "   1.5724369859526632e-06,\n",
       "   1.4646017234554165e-06,\n",
       "   1.3822279925079783e-06,\n",
       "   1.5445020835613832e-06,\n",
       "   1.8526021676734672e-06,\n",
       "   1.9559597603802104e-06,\n",
       "   1.9885644633177435e-06,\n",
       "   2.4523305910406634e-06,\n",
       "   3.2468574318045285e-06,\n",
       "   3.719894721143646e-06,\n",
       "   3.7442046050273348e-06,\n",
       "   3.7614881875924766e-06,\n",
       "   3.7618892747559585e-06,\n",
       "   3.3024348340404686e-06,\n",
       "   2.529775883886032e-06,\n",
       "   2.0542399852274684e-06,\n",
       "   1.862643557615229e-06,\n",
       "   1.4735155673406553e-06,\n",
       "   1.0410832373963785e-06,\n",
       "   1.1523952707648277e-06,\n",
       "   1.6942520915108616e-06,\n",
       "   2.0381778540468076e-06,\n",
       "   2.1176506379561033e-06,\n",
       "   2.2875433387525845e-06,\n",
       "   2.4854866751411464e-06,\n",
       "   2.5340777938254178e-06,\n",
       "   2.7599994609772693e-06,\n",
       "   3.3340934351144824e-06,\n",
       "   3.6508192806650186e-06,\n",
       "   3.3146543501061387e-06,\n",
       "   2.963182851090096e-06,\n",
       "   3.1686065540270647e-06,\n",
       "   3.434880454733502e-06,\n",
       "   3.213312766092713e-06,\n",
       "   2.8826575544371735e-06,\n",
       "   2.790705821098527e-06,\n",
       "   2.4478595150867477e-06,\n",
       "   1.6385704384447308e-06,\n",
       "   1.1557106063264655e-06,\n",
       "   1.4839439472780214e-06,\n",
       "   1.9145195437886287e-06,\n",
       "   1.8524374354456086e-06,\n",
       "   1.810745629882149e-06,\n",
       "   2.2683748284180183e-06,\n",
       "   2.7369533199816942e-06,\n",
       "   2.7450744255475e-06,\n",
       "   2.5967922283598455e-06,\n",
       "   2.506510327293654e-06,\n",
       "   2.1341320461942814e-06,\n",
       "   1.4719648788741324e-06,\n",
       "   1.0552827234278084e-06,\n",
       "   9.787012231754488e-07,\n",
       "   8.792146104497078e-07,\n",
       "   1.0046662737295264e-06,\n",
       "   1.956515689016669e-06,\n",
       "   3.3325497952318983e-06,\n",
       "   4.0684162740944885e-06,\n",
       "   4.1359780880156904e-06,\n",
       "   4.414036993694026e-06,\n",
       "   4.900105068372795e-06,\n",
       "   4.630865078070201e-06,\n",
       "   3.4443376080162125e-06,\n",
       "   2.2832659851701465e-06,\n",
       "   1.6344422419933835e-06,\n",
       "   1.0524008757784031e-06,\n",
       "   3.1114038279156375e-07,\n",
       "   -2.0908754549964215e-07,\n",
       "   -3.218150936845632e-07,\n",
       "   -1.7257441697893228e-07,\n",
       "   3.0709409770679486e-07,\n",
       "   1.1360067446730682e-06,\n",
       "   1.7648148968874011e-06,\n",
       "   1.7582998452780885e-06,\n",
       "   1.5831144537514774e-06,\n",
       "   1.838376647356199e-06,\n",
       "   2.2349147457134677e-06,\n",
       "   2.243330072815297e-06,\n",
       "   2.1186885987845017e-06,\n",
       "   2.312837523277267e-06,\n",
       "   2.532302914914908e-06,\n",
       "   2.3690445232205093e-06,\n",
       "   2.223844603577163e-06,\n",
       "   2.599239451228641e-06,\n",
       "   3.088900939474115e-06,\n",
       "   3.035644340343424e-06,\n",
       "   2.6228717615595087e-06,\n",
       "   2.400036237304448e-06,\n",
       "   2.265347575303167e-06,\n",
       "   1.8009956193054677e-06,\n",
       "   1.1436975455580978e-06,\n",
       "   7.516248388128588e-07,\n",
       "   7.15296380349173e-07,\n",
       "   8.849683581502177e-07,\n",
       "   1.212934876093641e-06,\n",
       "   1.4877867897666874e-06,\n",
       "   1.3104200888847117e-06,\n",
       "   7.779564157317509e-07,\n",
       "   5.467150003823917e-07,\n",
       "   8.138227940435172e-07,\n",
       "   9.567945653543575e-07,\n",
       "   5.875000397281838e-07,\n",
       "   1.6119199131026107e-07,\n",
       "   9.856918126160963e-08,\n",
       "   1.2726721365652338e-07,\n",
       "   -3.0819673924042945e-08,\n",
       "   -1.3591568404081045e-07,\n",
       "   -8.679985086246234e-08,\n",
       "   -2.7551902803679695e-07,\n",
       "   -7.771472496642673e-07,\n",
       "   -1.0099597602675203e-06,\n",
       "   -7.391026315417548e-07,\n",
       "   -5.943555834164727e-07,\n",
       "   -1.0310531024515512e-06,\n",
       "   -1.559963038744172e-06,\n",
       "   -1.573263602949737e-06,\n",
       "   -1.20922550195246e-06,\n",
       "   -9.016290505314828e-07,\n",
       "   -7.860601272113854e-07,\n",
       "   -9.509339520263893e-07,\n",
       "   -1.5454143067472614e-06,\n",
       "   -2.3064603738021106e-06,\n",
       "   -2.724058731473633e-06,\n",
       "   -2.8878439479740337e-06,\n",
       "   -3.2929387998592574e-06,\n",
       "   -3.758574166567996e-06,\n",
       "   -3.6046999412064906e-06,\n",
       "   -2.975662482640473e-06,\n",
       "   -2.758497657850967e-06,\n",
       "   -3.070137154281838e-06,\n",
       "   -3.1417948775924742e-06,\n",
       "   -2.80990093415312e-06,\n",
       "   -2.730590495048091e-06,\n",
       "   -2.9467480544553837e-06,\n",
       "   -2.774762606350123e-06,\n",
       "   -2.2380386326403823e-06,\n",
       "   -2.1263947473926237e-06,\n",
       "   -2.427431809337577e-06,\n",
       "   -2.182330945288413e-06,\n",
       "   -1.1459123925305903e-06,\n",
       "   -1.2347686606517527e-07,\n",
       "   3.7159799148867023e-07,\n",
       "   4.795015229319688e-07,\n",
       "   1.3322448921826435e-07,\n",
       "   -8.023095574571926e-07,\n",
       "   -1.8399470036456478e-06,\n",
       "   -2.6534203243500087e-06,\n",
       "   -3.889558229275281e-06,\n",
       "   -5.868411790288519e-06,\n",
       "   -7.371092124230927e-06,\n",
       "   -7.323998033825774e-06,\n",
       "   -6.6227757997694425e-06,\n",
       "   -6.494330591522157e-06,\n",
       "   -6.237202796910424e-06,\n",
       "   -4.6502004806825425e-06,\n",
       "   -2.5135771011264296e-06,\n",
       "   -1.4741492577741155e-06,\n",
       "   -1.5157858115344425e-06,\n",
       "   -1.6354501894966234e-06,\n",
       "   -1.9123592664982425e-06,\n",
       "   -2.872826371458359e-06,\n",
       "   -3.95034703615238e-06,\n",
       "   -4.415201146912295e-06,\n",
       "   -4.640896804630756e-06,\n",
       "   -4.942961822962388e-06,\n",
       "   -4.69562428406789e-06,\n",
       "   -3.7573877307295334e-06,\n",
       "   -3.2633624869049527e-06,\n",
       "   -3.588117806430091e-06,\n",
       "   -3.449683845246909e-06,\n",
       "   -2.50282255365164e-06,\n",
       "   -2.3311763470701408e-06,\n",
       "   -3.662691142380936e-06,\n",
       "   -5.0488738452258985e-06,\n",
       "   -5.503705324372277e-06,\n",
       "   -5.9362005231378134e-06,\n",
       "   -6.787164238630794e-06,\n",
       "   -6.966682576603489e-06,\n",
       "   -6.301752364379354e-06,\n",
       "   -6.311936431302456e-06,\n",
       "   -7.374660526693333e-06,\n",
       "   -7.803868356859311e-06,\n",
       "   -6.832440703874454e-06,\n",
       "   -5.7984816521639004e-06,\n",
       "   -5.578143372986233e-06,\n",
       "   -5.436999344965443e-06,\n",
       "   -5.0044350246025715e-06,\n",
       "   -4.821685251954477e-06,\n",
       "   -4.613821147358976e-06,\n",
       "   -3.59554269380169e-06,\n",
       "   -2.518927885830635e-06,\n",
       "   -2.8047547857568134e-06,\n",
       "   -4.031462594866753e-06,\n",
       "   -4.808094672625884e-06,\n",
       "   -5.44423619430745e-06,\n",
       "   -7.099784397723852e-06,\n",
       "   -9.11547067516949e-06,\n",
       "   -9.998855603043921e-06,\n",
       "   -1.0017375643656123e-05,\n",
       "   -1.0212655979557894e-05,\n",
       "   -9.979744390875567e-06,\n",
       "   -8.322359462908935e-06,\n",
       "   -6.300345376075711e-06,\n",
       "   -5.579151547863148e-06,\n",
       "   -5.719547061744379e-06,\n",
       "   -5.263697858026717e-06,\n",
       "   -4.376592187327333e-06,\n",
       "   -4.150499080424197e-06,\n",
       "   -4.5633532863575965e-06,\n",
       "   -5.004482773074415e-06,\n",
       "   -5.479371793626342e-06,\n",
       "   -5.858883923792746e-06,\n",
       "   -5.49387323189876e-06,\n",
       "   -4.60026967630256e-06,\n",
       "   -4.2364395085314754e-06,\n",
       "   -4.328894647187553e-06,\n",
       "   -3.8005694023013348e-06,\n",
       "   -2.962549842777662e-06,\n",
       "   -3.313871047794237e-06,\n",
       "   -4.754236215376295e-06,\n",
       "   -5.574270744546084e-06,\n",
       "   -5.460718966787681e-06,\n",
       "   -5.89114279136993e-06,\n",
       "   -7.293623639270663e-06,\n",
       "   -8.215529305743985e-06,\n",
       "   -7.660326446057297e-06,\n",
       "   -6.242593372007832e-06,\n",
       "   -4.8323827286367305e-06,\n",
       "   -3.7323388824006543e-06,\n",
       "   -3.0953924579080194e-06,\n",
       "   -2.774112772385706e-06,\n",
       "   -2.194703029090306e-06,\n",
       "   -1.4496814628728316e-06,\n",
       "   -1.6085521110653644e-06,\n",
       "   -2.9605407689814456e-06,\n",
       "   -4.258450644556433e-06,\n",
       "   -4.62922798760701e-06,\n",
       "   -4.636392986867577e-06,\n",
       "   -4.6178415686881635e-06,\n",
       "   -3.899445800925605e-06,\n",
       "   -2.5085503239097307e-06,\n",
       "   -1.6888131995074218e-06,\n",
       "   -2.000976110139163e-06,\n",
       "   -2.509618980184314e-06,\n",
       "   -2.56588168667804e-06,\n",
       "   -2.723940724536078e-06,\n",
       "   -3.523717396092252e-06,\n",
       "   -4.598161922331201e-06,\n",
       "   -5.161859007785097e-06,\n",
       "   -4.707742391474312e-06,\n",
       "   -3.378987003088696e-06,\n",
       "   -2.196307150370558e-06,\n",
       "   -2.0536983811325626e-06,\n",
       "   -2.362229224672774e-06,\n",
       "   -1.8533349930294207e-06,\n",
       "   -6.502728524537815e-07,\n",
       "   6.68283917093504e-08,\n",
       "   1.4647486068497528e-07,\n",
       "   3.144251365938544e-07,\n",
       "   3.5436653433862375e-07,\n",
       "   -3.6961239402444335e-07,\n",
       "   -1.143748477261397e-06,\n",
       "   -8.830337492327089e-07,\n",
       "   -5.432460881138468e-08,\n",
       "   2.4773916607045976e-07,\n",
       "   9.814898760396318e-08,\n",
       "   -1.254988717391825e-07,\n",
       "   -6.309863351816603e-07,\n",
       "   -9.872127293419908e-07,\n",
       "   -4.86457395254547e-07,\n",
       "   -3.908064627466956e-07,\n",
       "   -2.409439275652403e-06,\n",
       "   -4.7161120164673775e-06,\n",
       "   -4.045597052027006e-06,\n",
       "   -1.2628418062377023e-06,\n",
       "   2.3699200824012223e-07,\n",
       "   7.164534849835036e-07,\n",
       "   2.560754865044146e-06,\n",
       "   4.097264536540024e-06,\n",
       "   2.3005743514659116e-06,\n",
       "   -6.024372396495892e-07,\n",
       "   -7.603849212500791e-07,\n",
       "   -1.939955183161146e-07,\n",
       "   -2.5393708256160608e-06,\n",
       "   -5.158258318260778e-06,\n",
       "   -4.232216724631144e-06,\n",
       "   -2.6536449695413467e-06,\n",
       "   -3.972812010033522e-06,\n",
       "   -4.712796908279415e-06,\n",
       "   -1.8364926290814765e-06,\n",
       "   2.646658288085746e-07,\n",
       "   -1.0928769142992678e-06,\n",
       "   -1.1828556125692558e-06,\n",
       "   6.430436769733205e-07,\n",
       "   -2.444458004902117e-06,\n",
       "   -9.041490557137877e-06,\n",
       "   -8.2772494351957e-06,\n",
       "   -1.9747635633393656e-06,\n",
       "   -5.216174031374976e-06,\n",
       "   -1.6384783521061763e-05,\n",
       "   -1.4754552466911264e-05,\n",
       "   2.2491321942652576e-06,\n",
       "   1.1445072232163511e-05,\n",
       "   4.894368430541363e-06,\n",
       "   2.0172806216578465e-06,\n",
       "   8.607613381172996e-06,\n",
       "   4.6964760258561e-06,\n",
       "   -1.2296996828808915e-05,\n",
       "   -1.562541729072109e-05,\n",
       "   3.492985342745669e-06,\n",
       "   1.871997483249288e-05,\n",
       "   7.153063052101061e-06,\n",
       "   -3.9245096559170634e-05,\n",
       "   -0.0001325219782302156,\n",
       "   -0.0002518248511478305,\n",
       "   -0.0002968877088278532,\n",
       "   -0.0001723240129649639,\n",
       "   7.064482633722946e-05,\n",
       "   0.0002712217392399907,\n",
       "   0.00035384169314056635,\n",
       "   0.0003894426627084613,\n",
       "   0.0004527238488662988,\n",
       "   0.00053539959480986,\n",
       "   0.0006239003269001842,\n",
       "   0.000736686575692147,\n",
       "   0.0008460143581032753,\n",
       "   0.0008861722890287638,\n",
       "   0.0008811891311779618,\n",
       "   0.0009407312609255314,\n",
       "   0.0010873139835894108,\n",
       "   0.0012127186637371778,\n",
       "   0.001242246595211327,\n",
       "   0.0012076772982254624,\n",
       "   0.0011240743333473802,\n",
       "   0.0009483826579526067,\n",
       "   0.0007081293151713908,\n",
       "   0.0005149102071300149,\n",
       "   0.00039499797276221216,\n",
       "   0.0002587204799056053,\n",
       "   8.479413372697309e-05,\n",
       "   -3.2940490200417116e-05,\n",
       "   -7.513442687923089e-05,\n",
       "   -0.00015494100807700306,\n",
       "   -0.00031873356783762574,\n",
       "   -0.0004613639903254807,\n",
       "   -0.0005097968969494104,\n",
       "   -0.0005216694553382695,\n",
       "   -0.0005390909500420094,\n",
       "   -0.0005242051556706429,\n",
       "   -0.0005063462303951383,\n",
       "   -0.0006028193747624755,\n",
       "   -0.0008108731126412749,\n",
       "   -0.0009605811210349202,\n",
       "   -0.0009602175559848547,\n",
       "   -0.000917653611395508,\n",
       "   -0.0009433999075554311,\n",
       "   -0.001010379521176219,\n",
       "   -0.0010840948671102524,\n",
       "   -0.0012089202646166086,\n",
       "   -0.0013778253924101591,\n",
       "   -0.0014839235227555037,\n",
       "   -0.0014821174554526806,\n",
       "   -0.0014433467295020819,\n",
       "   -0.0013912254944443703,\n",
       "   -0.0012586602242663503,\n",
       "   -0.001063058851286769,\n",
       "   -0.0009385772282257676,\n",
       "   -0.0009214414749294519,\n",
       "   -0.0008810987928882241,\n",
       "   -0.0007421329501084983,\n",
       "   -0.0006040600128471851,\n",
       "   -0.0005581810837611556,\n",
       "   -0.000539668370038271,\n",
       "   -0.0004479498602449894,\n",
       "   -0.000288558192551136,\n",
       "   -0.00012843818694818765,\n",
       "   -1.5651137800887227e-05,\n",
       "   2.3900787709862925e-05,\n",
       "   1.7793656297726557e-05,\n",
       "   8.097897080006078e-05,\n",
       "   0.0002954969822894782,\n",
       "   0.0005617168499156833,\n",
       "   0.0007043926743790507,\n",
       "   0.0007160968380048871,\n",
       "   0.0007472370052710176,\n",
       "   0.0008637203136458993,\n",
       "   0.0009737382642924786,\n",
       "   0.001005580648779869,\n",
       "   0.0010085857938975096,\n",
       "   0.0010513786692172289,\n",
       "   0.0011397262569516897,\n",
       "   0.0012495556147769094,\n",
       "   0.0013424735516309738,\n",
       "   0.0013523803791031241,\n",
       "   0.0012500310549512506,\n",
       "   0.0011056349612772465,\n",
       "   0.0010063534136861563,\n",
       "   0.0009446066105738282,\n",
       "   0.0008622236200608313,\n",
       "   0.0007498797494918108,\n",
       "   0.0006163467769511044,\n",
       "   0.00042279064655303955,\n",
       "   0.00014432391617447138,\n",
       "   -0.00015137906302697957,\n",
       "   -0.00036997225834056735,\n",
       "   -0.0004910118877887726,\n",
       "   -0.0005478090024553239,\n",
       "   -0.0005736174643971026,\n",
       "   -0.0006151061388663948,\n",
       "   -0.0007184225833043456,\n",
       "   -0.000850495882332325,\n",
       "   -0.0009156133164651692,\n",
       "   -0.0008888310985639691,\n",
       "   -0.000843080400954932,\n",
       "   -0.0008226054487749934,\n",
       "   -0.0008006145944818854,\n",
       "   -0.0007823477499186993,\n",
       "   -0.000818124448414892,\n",
       "   -0.0008827643468976021,\n",
       "   -0.000877995858900249,\n",
       "   -0.0007919360650703311,\n",
       "   -0.0007264702580869198,\n",
       "   -0.000739302602596581,\n",
       "   -0.000791452475823462,\n",
       "   -0.0008648865623399615,\n",
       "   -0.000983883859589696,\n",
       "   -0.0011047087609767914,\n",
       "   -0.0011447659926488996,\n",
       "   -0.0011416689958423376,\n",
       "   -0.0012192294234409928,\n",
       "   -0.001374602084979415,\n",
       "   -0.0014671984827145934,\n",
       "   -0.001439157989807427,\n",
       "   -0.0013725175522267818,\n",
       "   -0.0013059743214398623,\n",
       "   -0.0011859764344990253,\n",
       "   -0.0010436634765937924,\n",
       "   -0.0010240939445793629,\n",
       "   -0.0011618982534855604,\n",
       "   -0.0012880819849669933,\n",
       "   -0.0012444952735677361,\n",
       "   -0.0010670132469385862,\n",
       "   -0.0008913702913559973,\n",
       "   -0.0007909383857622743,\n",
       "   -0.0007587102008983493,\n",
       "   -0.0007452272693626583,\n",
       "   -0.0006720233941450715,\n",
       "   -0.0004991869209334254,\n",
       "   -0.00029804304358549416,\n",
       "   -0.0001643152500037104,\n",
       "   -6.305763963609934e-05,\n",
       "   0.0001248140906682238,\n",
       "   0.00040175742469727993,\n",
       "   0.0006363099091686308,\n",
       "   0.0007693130755797029,\n",
       "   0.000900760293006897,\n",
       "   0.0011145186144858599,\n",
       "   0.001328016398474574,\n",
       "   0.0013997675850987434,\n",
       "   0.0013231838820502162,\n",
       "   0.0012403397122398019,\n",
       "   0.0012839981354773045,\n",
       "   0.0014488489832729101,\n",
       "   0.0016122099477797747,\n",
       "   0.0016608941368758678,\n",
       "   0.0015950938686728477,\n",
       "   0.001506850472651422,\n",
       "   0.001465515815652907,\n",
       "   0.0014500009128823876,\n",
       "   0.0013980179792270064,\n",
       "   0.0012882057344540954,\n",
       "   0.0011564388405531645,\n",
       "   0.0010518701747059822,\n",
       "   0.0009904381586238742,\n",
       "   0.0009431095095351338,\n",
       "   0.000875891069881618,\n",
       "   0.0008068041643127799,\n",
       "   0.0007878592004999518,\n",
       "   0.0008090756018646061,\n",
       "   0.0007726547191850841,\n",
       "   0.0006125420331954956,\n",
       "   0.00039160955930128694,\n",
       "   0.00021815174841322005,\n",
       "   0.00011316748714307323,\n",
       "   3.169586125295609e-05,\n",
       "   -3.394792656763457e-05,\n",
       "   -6.295675120782107e-05,\n",
       "   -8.057360537350178e-05,\n",
       "   -0.00012920194421894848,\n",
       "   -0.00018761976389214396,\n",
       "   -0.0002055745862890035,\n",
       "   -0.00019597513892222196,\n",
       "   -0.00021024409215897322,\n",
       "   -0.0002455689827911556,\n",
       "   -0.00025894970167428255,\n",
       "   -0.0002534321101848036,\n",
       "   -0.0002657596778590232,\n",
       "   -0.0002885031281039119,\n",
       "   -0.0002849313314072788,\n",
       "   -0.00026481255190446973,\n",
       "   -0.0002681900514289737,\n",
       "   -0.0002887207083404064,\n",
       "   -0.00028754823142662644,\n",
       "   -0.00026771827833727,\n",
       "   -0.0002646106877364218,\n",
       "   -0.0002766655234154314,\n",
       "   -0.0002722134522628039,\n",
       "   -0.0002523540169931948,\n",
       "   -0.00024661788484081626,\n",
       "   -0.00025600779918022454,\n",
       "   -0.0002558420819696039,\n",
       "   -0.00024295850016642362,\n",
       "   -0.0002340662176720798,\n",
       "   -0.00023027686984278262,\n",
       "   -0.00022272983915172517,\n",
       "   -0.000216341795749031,\n",
       "   -0.00021494796965271235,\n",
       "   -0.00020489699090830982,\n",
       "   -0.00018164326320402324,\n",
       "   -0.00016689737094566226,\n",
       "   -0.00016917940229177475,\n",
       "   -0.00016154641343746334,\n",
       "   -0.00012755616626236588,\n",
       "   -9.4452771008946e-05,\n",
       "   -8.85134722921066e-05,\n",
       "   -9.19222438824363e-05,\n",
       "   -7.731854566372931e-05,\n",
       "   -5.403402974479832e-05,\n",
       "   -4.60139344795607e-05,\n",
       "   -4.9240356020163745e-05,\n",
       "   -4.411057670949958e-05,\n",
       "   -2.8277812816668302e-05,\n",
       "   -1.3356077033677138e-05,\n",
       "   -5.4923671086726245e-06,\n",
       "   -6.527740879391786e-06,\n",
       "   -1.65467536135111e-05,\n",
       "   -2.350477734580636e-05,\n",
       "   -1.2041008631058503e-05,\n",
       "   9.476991181145422e-06,\n",
       "   1.4890762940922286e-05,\n",
       "   -8.995152711577248e-07,\n",
       "   -1.4633979844802525e-05,\n",
       "   -1.2388916729833e-05,\n",
       "   -7.412662398564862e-06,\n",
       "   -1.3504708476830274e-05,\n",
       "   -2.551635952841025e-05,\n",
       "   -3.470298179308884e-05,\n",
       "   -4.093161260243505e-05,\n",
       "   -4.272969817975536e-05,\n",
       "   -3.60443809768185e-05,\n",
       "   -2.6150522899115458e-05,\n",
       "   -2.3028354917187244e-05,\n",
       "   -2.2007552615832537e-05,\n",
       "   -1.088394765247358e-05,\n",
       "   5.76416732656071e-06,\n",
       "   9.672410669736564e-06,\n",
       "   -1.9208303001505556e-06,\n",
       "   -1.0894322258536704e-05,\n",
       "   -6.212748758116504e-06,\n",
       "   1.9739309209398925e-06,\n",
       "   1.24237624277157e-06,\n",
       "   -5.039416009822162e-06,\n",
       "   -6.049647709005512e-06,\n",
       "   1.988248641282553e-06,\n",
       "   1.2896429325337522e-05,\n",
       "   1.7749702237779275e-05,\n",
       "   1.2860680726589635e-05,\n",
       "   3.880961230606772e-06,\n",
       "   -9.111512326853699e-07,\n",
       "   -2.3690447505941847e-06,\n",
       "   -1.0020296031143516e-05,\n",
       "   -2.6243309548590332e-05,\n",
       "   -4.0660612285137177e-05,\n",
       "   -4.4957072532270104e-05,\n",
       "   -4.339642691775225e-05,\n",
       "   -4.326905036577955e-05,\n",
       "   -4.333285323809832e-05,\n",
       "   -4.07532716053538e-05,\n",
       "   -3.901200398104265e-05,\n",
       "   -4.078017809661105e-05,\n",
       "   -3.951753387809731e-05,\n",
       "   -2.9793140129186213e-05,\n",
       "   -1.870043524831999e-05,\n",
       "   -1.6758391211624257e-05,\n",
       "   -2.2145643015392125e-05,\n",
       "   -2.3615750251337886e-05,\n",
       "   -1.6911026250454597e-05,\n",
       "   -8.226933459809516e-06,\n",
       "   -3.1612707971362397e-06,\n",
       "   -4.6563221189899195e-07,\n",
       "   1.7982904410018818e-06,\n",
       "   2.912174750235863e-06,\n",
       "   2.646770099090645e-06,\n",
       "   ...],\n",
       "  'path': 'C:\\\\Users\\\\T H E J\\\\Desktop\\\\Badaga_Corpus-v.0.1.0\\\\clips\\\\F002_1_1.mp3',\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': 'MANAYA AENA UDHAKA '}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the data after processing \n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d65fd-fa6a-4ef8-9ed2-2424f62452ff",
   "metadata": {},
   "source": [
    "###  Preparing Audio and Transcriptions for Wav2Vec2 Training using `Wav2Vec2Processor`\n",
    "\n",
    "* Finally, we can leverage `Wav2Vec2Processor` to process the data to the format expected by `Wav2Vec2ForCTC` for training. To do so let's make use of Dataset's 'map' function.\n",
    "\n",
    "* First, we load and resample the audio data, simply by calling `batch[\"audio\"]`.\n",
    "* Second, we extract the `input_values` from the loaded audio file. In our case, the `Wav2Vec2Processor` only normalizes the data.\n",
    "\n",
    "* Third, we encode the transcriptions to label ids.\n",
    "\n",
    "* **Note**: This mapping function is a good example of how the `Wav2Vec2Processor` class should be used. In \"normal\" context, calling `processor(...)` is redirected to `Wav2Vec2FeatureExtractor`'s call method. When wrapping the processor into the `as_target_processor` context, however, the same method is redirected to `Wav2Vec2CTCTokenizer`'s call method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1da6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pass the audio files in batch\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e1d1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train Dataset:   0%|                                      | 0/8365 [00:00<?, ? examples/s]C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Processing Train Dataset: 100%|███████████████████████████| 8365/8365 [02:34<00:00, 54.01 examples/s]\n",
      "Processing Test Dataset: 100%|████████████████████████████| 1469/1469 [00:26<00:00, 56.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Map function with progress bar\n",
    "train_dataset = train_dataset.map(prepare_dataset, remove_columns=train_dataset.column_names, desc=\"Processing Train Dataset\")\n",
    "test_dataset = test_dataset.map(prepare_dataset, remove_columns=test_dataset.column_names, desc=\"Processing Test Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953053b1-3207-4659-b9a4-f8f780755d1b",
   "metadata": {},
   "source": [
    "### Training Setup\n",
    "\n",
    "### Set the data collator to handle and pass the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497dac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function for data collator\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c1b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collator\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5b223-a6d1-41c5-8f3d-c72b1eba94fb",
   "metadata": {},
   "source": [
    "### Defining the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e94c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the correct metric loading function\n",
    "import evaluate\n",
    "\n",
    "# Load Word Error Rate (WER) metric\n",
    "wer_metric = evaluate.load(\"wer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f141d-9ac5-40d0-b2f8-b68986bbc665",
   "metadata": {},
   "source": [
    "### Function for evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1585b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing the WER \n",
    "import numpy as np\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96744f-2165-419c-95c7-e0e3b25e286c",
   "metadata": {},
   "source": [
    "### Loading the pre-trained model\n",
    "* Here we use 'xls-r-53' variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b7b9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:2176: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5. Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\T H E J\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-large-xlsr-53. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Load Wav2Vec2 model and move to GPU\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ").to(device)  # Move model to GPU\n",
    "\n",
    "# Enable gradient checkpointing to save memory\n",
    "model.freeze_feature_extractor()\n",
    "model.gradient_checkpointing_enable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc25a3a-9e94-4440-a32b-c15644ef6689",
   "metadata": {},
   "source": [
    "### Defining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01a2f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# setting up the arguments for training\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"wav2vec2-badaga\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=10,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd0c6a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T H E J\\AppData\\Local\\Temp\\ipykernel_20488\\1840994926.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# setting up the trainer\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdba247-a382-47ad-a453-ada3c0d39575",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6cec071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10460' max='10460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10460/10460 29:03:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.782800</td>\n",
       "      <td>3.359624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.911400</td>\n",
       "      <td>2.877742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.803000</td>\n",
       "      <td>2.808927</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.808800</td>\n",
       "      <td>2.712787</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.566500</td>\n",
       "      <td>2.359767</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.720700</td>\n",
       "      <td>1.329751</td>\n",
       "      <td>0.958451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.621400</td>\n",
       "      <td>1.025979</td>\n",
       "      <td>0.789267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.590900</td>\n",
       "      <td>0.922109</td>\n",
       "      <td>0.686497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.244500</td>\n",
       "      <td>0.864935</td>\n",
       "      <td>0.650929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.153100</td>\n",
       "      <td>0.774906</td>\n",
       "      <td>0.564684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.809081</td>\n",
       "      <td>0.562323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.113300</td>\n",
       "      <td>0.670755</td>\n",
       "      <td>0.524394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.006900</td>\n",
       "      <td>0.671614</td>\n",
       "      <td>0.479698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.605770</td>\n",
       "      <td>0.426346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.878300</td>\n",
       "      <td>0.632645</td>\n",
       "      <td>0.418004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.859800</td>\n",
       "      <td>0.590852</td>\n",
       "      <td>0.406830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.773100</td>\n",
       "      <td>0.555390</td>\n",
       "      <td>0.388259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>0.573511</td>\n",
       "      <td>0.392037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.380862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.914400</td>\n",
       "      <td>0.538115</td>\n",
       "      <td>0.375511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.467600</td>\n",
       "      <td>0.536516</td>\n",
       "      <td>0.354580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>0.339943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.506287</td>\n",
       "      <td>0.345609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.548100</td>\n",
       "      <td>0.542266</td>\n",
       "      <td>0.346553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0.371577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.495711</td>\n",
       "      <td>0.344350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.496708</td>\n",
       "      <td>0.329084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.483736</td>\n",
       "      <td>0.318382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.494018</td>\n",
       "      <td>0.327982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.478546</td>\n",
       "      <td>0.311772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.469915</td>\n",
       "      <td>0.301700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.469960</td>\n",
       "      <td>0.310513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.436400</td>\n",
       "      <td>0.470646</td>\n",
       "      <td>0.288637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>0.458856</td>\n",
       "      <td>0.304847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.450633</td>\n",
       "      <td>0.296191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.479231</td>\n",
       "      <td>0.289424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.286906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.441617</td>\n",
       "      <td>0.278722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.441251</td>\n",
       "      <td>0.289581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.430875</td>\n",
       "      <td>0.278093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.334600</td>\n",
       "      <td>0.412186</td>\n",
       "      <td>0.268650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.418945</td>\n",
       "      <td>0.268492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.473982</td>\n",
       "      <td>0.260466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.426328</td>\n",
       "      <td>0.271955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.421516</td>\n",
       "      <td>0.262354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.412636</td>\n",
       "      <td>0.252282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.414806</td>\n",
       "      <td>0.257476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.392654</td>\n",
       "      <td>0.261410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.402156</td>\n",
       "      <td>0.255587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.398653</td>\n",
       "      <td>0.249292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.392723</td>\n",
       "      <td>0.249292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.392763</td>\n",
       "      <td>0.247561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.382329</td>\n",
       "      <td>0.250393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.386132</td>\n",
       "      <td>0.241737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.375499</td>\n",
       "      <td>0.238118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.495900</td>\n",
       "      <td>0.384547</td>\n",
       "      <td>0.241737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.383305</td>\n",
       "      <td>0.239062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.366008</td>\n",
       "      <td>0.234498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>0.368838</td>\n",
       "      <td>0.223639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.364550</td>\n",
       "      <td>0.227731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.370948</td>\n",
       "      <td>0.226944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.430800</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>0.231822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.384472</td>\n",
       "      <td>0.219232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.373349</td>\n",
       "      <td>0.224111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.368894</td>\n",
       "      <td>0.220176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.369915</td>\n",
       "      <td>0.219075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.356984</td>\n",
       "      <td>0.217029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.360861</td>\n",
       "      <td>0.216242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.356568</td>\n",
       "      <td>0.209632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.351160</td>\n",
       "      <td>0.214196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.349135</td>\n",
       "      <td>0.200031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.364610</td>\n",
       "      <td>0.201763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>0.344605</td>\n",
       "      <td>0.199874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>0.348786</td>\n",
       "      <td>0.198458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.359321</td>\n",
       "      <td>0.195625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.338858</td>\n",
       "      <td>0.199717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.351688</td>\n",
       "      <td>0.194681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.339586</td>\n",
       "      <td>0.195467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.339475</td>\n",
       "      <td>0.186025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.341896</td>\n",
       "      <td>0.190116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.354575</td>\n",
       "      <td>0.191533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.341018</td>\n",
       "      <td>0.180988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.330041</td>\n",
       "      <td>0.182247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.330754</td>\n",
       "      <td>0.183979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.351939</td>\n",
       "      <td>0.179572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.339648</td>\n",
       "      <td>0.182090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.325002</td>\n",
       "      <td>0.181618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.324661</td>\n",
       "      <td>0.179729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.327057</td>\n",
       "      <td>0.178470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.339985</td>\n",
       "      <td>0.178628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.346827</td>\n",
       "      <td>0.180201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.176110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.329157</td>\n",
       "      <td>0.181146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.325816</td>\n",
       "      <td>0.175480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.323266</td>\n",
       "      <td>0.172175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>0.326439</td>\n",
       "      <td>0.170916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.326681</td>\n",
       "      <td>0.171703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.325253</td>\n",
       "      <td>0.170916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.323038</td>\n",
       "      <td>0.169657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.332870</td>\n",
       "      <td>0.171073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.347300</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.168713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.322094</td>\n",
       "      <td>0.167768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>0.322893</td>\n",
       "      <td>0.166824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.322372</td>\n",
       "      <td>0.168713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\T H E J\\anaconda3\\envs\\gpu_fast\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10460, training_loss=0.68324225282236, metrics={'train_runtime': 104636.5165, 'train_samples_per_second': 0.799, 'train_steps_per_second': 0.1, 'total_flos': 6.082338111187655e+18, 'train_loss': 0.68324225282236, 'epoch': 10.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-3900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4500/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4700/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-4900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-4900/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-4900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5100/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-4900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5500/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5700/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-5900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-5900/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-5900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6100/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-5900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6700/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-6900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-6900/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-6900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7100/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-6900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7300/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7500/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7700/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-7900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-7900/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-7900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-7900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8500/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8700/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-8900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-8900/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-8900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9100/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-8900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9500\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9500/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9500/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9500/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9300] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9600\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9600/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9600/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9400] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9700\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9700/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9700/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9500] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9800\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9800/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9800/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9600] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-9900\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9900/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-9900/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-9900/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9700] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-10000\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10000/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-10000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10000/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9800] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-10100\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10100/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-10100/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-9900] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-10200\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10200/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-10200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-10000] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-10300\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10300/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-10300/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-10100] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1469\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to wav2vec2-rbg-badaga-stt/checkpoint-10400\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10400/config.json\n",
      "Model weights saved in wav2vec2-rbg-badaga-stt/checkpoint-10400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-rbg-badaga-stt/checkpoint-10400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-rbg-badaga-stt/checkpoint-10200] due to args.save_total_limit\n",
      "/home/ubuntu/environments/corepool/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1055: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10460, training_loss=0.6890156001821303, metrics={'train_runtime': 25906.7641, 'train_samples_per_second': 3.229, 'train_steps_per_second': 0.404, 'total_flos': 6.123033781781698e+18, 'train_loss': 0.6890156001821303, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce6d89-0ce9-407f-93b3-d2cae4fb00e8",
   "metadata": {},
   "source": [
    "### Load Fine-Tuned Wav2Vec2 Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92088535-6b7d-41df-bac9-3373a12c593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "\n",
    "# Path to your fine-tuned Wav2Vec2 model checkpoint\n",
    "model_path = r\"C:\\Users\\T H E J\\Downloads\\wav2vec2-badaga\\checkpoint-10460\"\n",
    "\n",
    "# Load the processor and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path)\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fb779-f214-4a76-91f6-d052e1492e31",
   "metadata": {},
   "source": [
    "### Perform Inference with Fine-Tuned Wav2Vec2 Model on Audio Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effbd9de-2bb5-48f7-b947-00db31a4e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ Transcription: E BANDI ALLIGA OORA\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Load audio (16kHz, mono)\n",
    "speech_array, sampling_rate = torchaudio.load(\n",
    "    r\"C:\\Users\\T H E J\\Desktop\\Badaga_Corpus-v.0.1.0\\clips\\F001_1_52.mp3\"\n",
    ")\n",
    "\n",
    "# Resample if needed\n",
    "if sampling_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "    speech_array = resampler(speech_array)\n",
    "\n",
    "# Mono channel\n",
    "speech_array = speech_array.squeeze()\n",
    "\n",
    "# Tokenize\n",
    "inputs = processor(speech_array, return_tensors=\"pt\", sampling_rate=16000)\n",
    "inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# Decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "print(\"🗣️ Transcription:\", transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656674b-fd03-4b91-bab1-d91a90e63eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_fast)",
   "language": "python",
   "name": "gpu_fast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
